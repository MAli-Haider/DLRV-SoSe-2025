{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbzPAogQDcr7",
        "outputId": "1f770095-39fe-4ec6-e115-3dbe7abffe79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-6fe50f88-2376-59df-c7bd-100ef6d1b6e3)\n",
            "Torch: 2.8.0+cu126 | CUDA available: True | Python: 3.12.11\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "DATASET_ROOT: /content/drive/MyDrive/DLRV/DATASET\n"
          ]
        }
      ],
      "source": [
        "# (Optional) GPU + Torch sanity\n",
        "!nvidia-smi -L || echo \"No GPU found\"\n",
        "import torch, platform\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available(), \"| Python:\", platform.python_version())\n",
        "\n",
        "# Mount Google Drive (your dataset lives here)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/DLRV/DATASET\"  # <-- your path\n",
        "print(\"DATASET_ROOT:\", DATASET_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf yolov7\n",
        "!git clone https://github.com/WongKinYiu/yolov7 -q\n",
        "%cd yolov7\n",
        "!python -c \"import pathlib; import inspect, train, test, detect; print('OK:', pathlib.Path(inspect.getfile(train)).parent)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUC77k7gD5HI",
        "outputId": "036dfd07-1fbf-4d65-d835-134e3323db84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/yolov7\n",
            "2025-09-07 21:47:52.206624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757281672.226317    1472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757281672.232105    1472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757281672.246781    1472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757281672.246812    1472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757281672.246816    1472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757281672.246819    1472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-07 21:47:52.251160: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "OK: /content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSIF_DIR = \"/content/drive/MyDrive/DLRV/DATASET\"  # has TRAIN/ and TEST/\n",
        "YOLO_OUT    = \"/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN\"  # new dataset\n",
        "VAL_SPLIT   = 0.20  # from TRAIN -> train/val\n"
      ],
      "metadata": {
        "id": "h2bhgLIEQqCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, io, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "CLASSIF = Path(CLASSIF_DIR)\n",
        "QUAR    = CLASSIF / \"bad\"\n",
        "IMG_EXT = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}\n",
        "MIN_WH  = 20\n",
        "\n",
        "def is_ok_image(p: Path):\n",
        "    try:\n",
        "        with Image.open(p) as im:\n",
        "            im.verify()            # header/structure\n",
        "        with Image.open(p) as im2:\n",
        "            im2.load()             # full decode\n",
        "            w, h = im2.size\n",
        "        if w < MIN_WH or h < MIN_WH:\n",
        "            return False, f\"too_small_{w}x{h}\"\n",
        "    except Exception as e:\n",
        "        return False, f\"pillow_{type(e).__name__}\"\n",
        "    # extra cv2 decode check\n",
        "    try:\n",
        "        data = np.fromfile(str(p), dtype=np.uint8)\n",
        "        img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
        "        if img is None: return False, \"cv2_imdecode_failed\"\n",
        "    except Exception:\n",
        "        return False, \"cv2_exception\"\n",
        "    return True, \"ok\"\n",
        "\n",
        "rows = []\n",
        "for split in [\"TRAIN\",\"TEST\"]:\n",
        "    for img in (CLASSIF/split).rglob(\"*\"):\n",
        "        if not img.is_file() or img.suffix.lower() not in IMG_EXT:\n",
        "            continue\n",
        "        ok, reason = is_ok_image(img)\n",
        "        lbl = None  # (no labels yet at this stage)\n",
        "        rows.append({\"split\":split, \"image\":str(img), \"status\":\"keep\" if ok else \"quarantine\", \"reason\":reason})\n",
        "        if not ok:\n",
        "            qdst = QUAR / split / img.name\n",
        "            qdst.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.move(str(img), str(qdst))\n",
        "\n",
        "report = pd.DataFrame(rows)\n",
        "report_path = CLASSIF / \"clean_report.csv\"\n",
        "report.to_csv(report_path, index=False)\n",
        "print(\"Saved:\", report_path)\n",
        "report[\"status\"].value_counts(dropna=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "oIhgnuvHQt5R",
        "outputId": "60d9cd70-187b-49ac-a905-e6aa246f305b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/DLRV/DATASET/clean_report.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status\n",
              "keep          1550\n",
              "quarantine       1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>keep</th>\n",
              "      <td>1550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quarantine</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, math\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "YOLO = Path(YOLO_OUT)\n",
        "for p in [YOLO/\"images/train\", YOLO/\"labels/train\", YOLO/\"images/val\", YOLO/\"labels/val\", YOLO/\"images/test\", YOLO/\"labels/test\"]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def list_images(folder):\n",
        "    return [p for p in Path(folder).rglob(\"*\") if p.suffix.lower() in IMG_EXT]\n",
        "\n",
        "classes = sorted([d.name for d in (CLASSIF/\"TRAIN\").iterdir() if d.is_dir()])\n",
        "cls2id  = {c:i for i,c in enumerate(classes)}\n",
        "\n",
        "def write_fullbox(lbl_path: Path, cid: int):\n",
        "    lbl_path.write_text(f\"{cid} 0.5 0.5 1.0 1.0\\n\", encoding=\"utf-8\")\n",
        "\n",
        "# TRAIN -> train/val; TEST -> test\n",
        "import shutil\n",
        "random.seed(42)\n",
        "for split_in, split_out in [(\"TRAIN\",\"train\"), (\"TEST\",\"test\")]:\n",
        "    for cls in classes:\n",
        "        imgs = list_images(CLASSIF/split_in/cls)\n",
        "        if split_out == \"train\":\n",
        "            random.shuffle(imgs)\n",
        "            k = int(math.floor(len(imgs)*(1-VAL_SPLIT)))\n",
        "            parts = [(\"train\", imgs[:k]), (\"val\", imgs[k:])]\n",
        "        else:\n",
        "            parts = [(\"test\", imgs)]\n",
        "        for out, files in parts:\n",
        "            for src in files:\n",
        "                # only proceed if file still exists (not quarantined)\n",
        "                if not src.exists():\n",
        "                    continue\n",
        "                # ensure readable RGB (already checked, but double-safe)\n",
        "                try:\n",
        "                    Image.open(src).convert(\"RGB\")\n",
        "                except Exception:\n",
        "                    continue\n",
        "                dst_img = YOLO/f\"images/{out}/{cls}__{src.stem}{src.suffix.lower()}\"\n",
        "                dst_lbl = YOLO/f\"labels/{out}/{cls}__{src.stem}.txt\"\n",
        "                shutil.copy2(src, dst_img)\n",
        "                write_fullbox(dst_lbl, cls2id[cls])\n",
        "\n",
        "print(\"Classes:\", classes)\n",
        "print(\"YOLO dataset root:\", YOLO)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aekZvrFmQvce",
        "outputId": "31c4f3c1-a39d-44e6-805e-c3f15791f31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
            "YOLO dataset root: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "DATA_YAML = \"/content/yolov7/data/yoga_raw_clean.yaml\"\n",
        "cfg = {\n",
        "    \"train\": str((YOLO/\"images/train\").resolve()),\n",
        "    \"val\":   str((YOLO/\"images/val\").resolve()),\n",
        "    \"test\":  str((YOLO/\"images/test\").resolve()) if (YOLO/\"images/test\").exists() else \"\",\n",
        "    \"nc\": len(classes),\n",
        "    \"names\": classes\n",
        "}\n",
        "with open(DATA_YAML, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "print(open(DATA_YAML).read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQd1_hVIQwws",
        "outputId": "1a98e7b9-adb0-4837-d0a0-68d8e72aaa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/train\n",
            "val: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/val\n",
            "test: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test\n",
            "nc: 5\n",
            "names:\n",
            "- downdog\n",
            "- goddess\n",
            "- plank\n",
            "- tree\n",
            "- warrior2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from inside your current Colab runtime\n",
        "%cd /content\n",
        "!rm -rf yolov7\n",
        "!git clone https://github.com/WongKinYiu/yolov7 -q\n",
        "%cd yolov7\n",
        "!git checkout main -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vBw2yZ0R32g",
        "outputId": "a5e6e098-5beb-48db-b24f-a32f75940a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This file is auto-imported by Python on start (module: site -> sitecustomize)\n",
        "%cd /content/yolov7\n",
        "code = r\"\"\"\n",
        "# Auto-loaded before train.py runs.\n",
        "# Allowlist YOLOv7's model class so torch.load(weights_only=True) can unpickle it safely.\n",
        "try:\n",
        "    import models.yolo as yolo\n",
        "    import torch.serialization as ts\n",
        "    ts.add_safe_globals([yolo.Model])\n",
        "except Exception:\n",
        "    # If anything goes wrong, don't block startup.\n",
        "    pass\n",
        "\"\"\"\n",
        "open(\"sitecustomize.py\",\"w\", encoding=\"utf-8\").write(code)\n",
        "print(\"Wrote /content/yolov7/sitecustomize.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwSGKjJSQC6",
        "outputId": "83c8316d-76f3-4e9b-bc10-9517eb556a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Wrote /content/yolov7/sitecustomize.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "!wget -q https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt -O yolov7-tiny.pt\n",
        "RUN_NAME = \"y7_tiny_raw_clean\"\n",
        "!python train.py --workers 8 --device 0 --batch-size 16 --img 640 --epochs 50 \\\n",
        "  --data {DATA_YAML} --weights yolov7-tiny.pt --name {RUN_NAME}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lru99-3AQyvl",
        "outputId": "cb3579fe-1588-4dbb-9b7a-4e3e5e11904b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "2025-09-07 22:25:31.969934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757283931.989890   13255 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757283931.995888   13255 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757283932.011524   13255 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757283932.011550   13255 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757283932.011554   13255 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757283932.011557   13255 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-07 22:25:32.016200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 587, in <module>\n",
            "    opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov7/utils/general.py\", line 151, in check_file\n",
            "    assert len(files), f'File Not Found: {file}'  # assert file was found\n",
            "           ^^^^^^^^^^\n",
            "AssertionError: File Not Found: /content/yolov7/data/yoga_raw_clean.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Your classification dataset (has TRAIN/ and TEST/)\n",
        "CLASSIF_DIR = Path(\"/content/drive/MyDrive/DLRV/DATASET\")\n",
        "\n",
        "# The YOLO-converted, cleaned dataset you trained on earlier\n",
        "YOLO_DATA_ROOT = Path(\"/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN\")\n",
        "\n",
        "assert CLASSIF_DIR.exists(), f\"Missing: {CLASSIF_DIR}\"\n",
        "assert YOLO_DATA_ROOT.exists(), f\"Missing: {YOLO_DATA_ROOT} (run the conversion/clean step first)\"\n",
        "\n",
        "# Derive class names from the class folders under TRAIN/\n",
        "classes = sorted([d.name for d in (CLASSIF_DIR/\"TRAIN\").iterdir() if d.is_dir()])\n",
        "print(\"Classes:\", classes)\n",
        "print(\"YOLO images:\", (YOLO_DATA_ROOT/'images').exists(), \"labels:\", (YOLO_DATA_ROOT/'labels').exists())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cShVqwMpSz9T",
        "outputId": "9cf2ad5d-fa00-4acb-af4a-588ab97efe64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
            "YOLO images: True labels: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml, os\n",
        "\n",
        "DATA_YAML = \"/content/yolov7/data/yoga_raw_clean.yaml\"\n",
        "cfg = {\n",
        "    \"train\": str((YOLO_DATA_ROOT/\"images/train\").resolve()),\n",
        "    \"val\":   str((YOLO_DATA_ROOT/\"images/val\").resolve()),\n",
        "    \"test\":  str((YOLO_DATA_ROOT/\"images/test\").resolve()) if (YOLO_DATA_ROOT/\"images/test\").exists() else \"\",\n",
        "    \"nc\": len(classes),\n",
        "    \"names\": classes\n",
        "}\n",
        "\n",
        "os.makedirs(\"/content/yolov7/data\", exist_ok=True)\n",
        "with open(DATA_YAML, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)\n",
        "\n",
        "print(\"Wrote YAML to:\", DATA_YAML)\n",
        "print(open(DATA_YAML, \"r\", encoding=\"utf-8\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1I4xyuSS18w",
        "outputId": "cfc2260f-bac2-4b17-8875-b6fa43fb3301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote YAML to: /content/yolov7/data/yoga_raw_clean.yaml\n",
            "train: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/train\n",
            "val: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/val\n",
            "test: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test\n",
            "nc: 5\n",
            "names:\n",
            "- downdog\n",
            "- goddess\n",
            "- plank\n",
            "- tree\n",
            "- warrior2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "for k in (\"train\",\"val\",\"test\"):\n",
        "    p = cfg[k]\n",
        "    if p:\n",
        "        print(k, \"ok:\", Path(p).exists(), \"->\", p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y_zrEwcS3av",
        "outputId": "1a043452-aadc-4858-85fc-cfb7f57bb230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train ok: True -> /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/train\n",
            "val ok: True -> /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/val\n",
            "test ok: True -> /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "YOLO_DATA_ROOT = Path(\"/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN\")  # <- the one used in your YAML\n",
        "assert (YOLO_DATA_ROOT/\"images/train\").exists(), \"images/train missing\"\n",
        "assert (YOLO_DATA_ROOT/\"labels/train\").exists(), \"labels/train missing\"\n",
        "print(\"Cleaning:\", YOLO_DATA_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKfdnvdSVk6f",
        "outputId": "733b5667-5d78-4ebb-cebe-39628f56c50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, io, shutil, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageFile\n",
        "import cv2\n",
        "\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}\n",
        "MIN_WH = 20\n",
        "QUAR   = YOLO_DATA_ROOT/\"bad\"\n",
        "\n",
        "def has_jpeg_eoi(p: Path):\n",
        "    if p.suffix.lower() not in {\".jpg\",\".jpeg\"}: return True\n",
        "    try:\n",
        "        with open(p, \"rb\") as f:\n",
        "            f.seek(-2, os.SEEK_END)\n",
        "            return f.read() == b\"\\xff\\xd9\"\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def pillow_verify_and_load(p: Path):\n",
        "    try:\n",
        "        with Image.open(p) as im:\n",
        "            im.verify()\n",
        "        with Image.open(p) as im2:\n",
        "            im2.load()\n",
        "            w,h = im2.size\n",
        "        if w < MIN_WH or h < MIN_WH:\n",
        "            return False, f\"too_small_{w}x{h}\"\n",
        "        return True, \"ok\"\n",
        "    except Exception as e:\n",
        "        return False, f\"pillow_{type(e).__name__}\"\n",
        "\n",
        "def cv2_can_read(p: Path):\n",
        "    try:\n",
        "        buf = np.fromfile(str(p), dtype=np.uint8)\n",
        "        img = cv2.imdecode(buf, cv2.IMREAD_COLOR)\n",
        "        return img is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def try_reencode(src: Path) -> bool:\n",
        "    \"\"\"Try to salvage by loading with truncated allowed, then re-encoding to a clean JPEG.\"\"\"\n",
        "    try:\n",
        "        # allow truncated just for the read attempt\n",
        "        old = ImageFile.LOAD_TRUNCATED_IMAGES\n",
        "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "        with Image.open(src) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            tmp = src.with_suffix(\".fixing.jpg\")\n",
        "            im.save(tmp, \"JPEG\", quality=95, optimize=True)\n",
        "        ImageFile.LOAD_TRUNCATED_IMAGES = old\n",
        "        # verify the new file strictly\n",
        "        ok, _ = pillow_verify_and_load(tmp)\n",
        "        if ok and has_jpeg_eoi(tmp):\n",
        "            shutil.move(str(tmp), str(src))\n",
        "            return True\n",
        "        tmp.unlink(missing_ok=True)\n",
        "    except Exception:\n",
        "        pass\n",
        "    finally:\n",
        "        try: ImageFile.LOAD_TRUNCATED_IMAGES = old\n",
        "        except: pass\n",
        "    return False\n",
        "\n",
        "def move_with_label(img_path: Path, split: str):\n",
        "    lbl_src = (YOLO_DATA_ROOT/\"labels\"/split/img_path.name).with_suffix(\".txt\")\n",
        "    dst_img = QUAR/\"images\"/split/img_path.name\n",
        "    dst_lbl = QUAR/\"labels\"/split/lbl_src.name\n",
        "    dst_img.parent.mkdir(parents=True, exist_ok=True)\n",
        "    dst_lbl.parent.mkdir(parents=True, exist_ok=True)\n",
        "    shutil.move(str(img_path), str(dst_img))\n",
        "    if lbl_src.exists():\n",
        "        shutil.move(str(lbl_src), str(dst_lbl))\n",
        "\n",
        "def clean_split(split: str):\n",
        "    rows = []\n",
        "    img_dir = YOLO_DATA_ROOT/\"images\"/split\n",
        "    if not img_dir.exists(): return rows\n",
        "    for p in img_dir.rglob(\"*\"):\n",
        "        if not p.is_file() or p.suffix.lower() not in IMG_EXTS:\n",
        "            continue\n",
        "\n",
        "        ok1, r1 = pillow_verify_and_load(p)\n",
        "        ok2 = has_jpeg_eoi(p)\n",
        "        ok3 = cv2_can_read(p)\n",
        "        ok = ok1 and ok2 and ok3\n",
        "\n",
        "        status = \"keep\"\n",
        "        action = \"none\"\n",
        "        reason = \"ok\" if ok else \"|\".join([r1 if not ok1 else \"\",\n",
        "                                           \"bad_eoi\" if not ok2 else \"\",\n",
        "                                           \"cv2_fail\" if not ok3 else \"\"]).strip(\"|\")\n",
        "\n",
        "        if not ok:\n",
        "            # try repair once\n",
        "            if p.suffix.lower() in {\".jpg\",\".jpeg\"} and try_reencode(p):\n",
        "                status, action, reason = \"keep\", \"reencoded\", reason+\"->fixed\"\n",
        "            else:\n",
        "                status, action = \"quarantine\", \"moved\"\n",
        "                move_with_label(p, split)\n",
        "\n",
        "        rows.append({\"split\":split,\"image\":str(p),\"status\":status,\"action\":action,\"reason\":reason})\n",
        "    return rows\n",
        "\n",
        "all_rows = []\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    print(\"Scanning:\", split)\n",
        "    all_rows += clean_split(split)\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "rep = YOLO_DATA_ROOT/\"clean_fix_report.csv\"\n",
        "df.to_csv(rep, index=False)\n",
        "print(\"Saved report:\", rep)\n",
        "df[\"status\"].value_counts(dropna=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Izh_k0swVoO7",
        "outputId": "6fc362b6-9954-4bee-bbc0-65d66d4324d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning: train\n",
            "Scanning: val\n",
            "Scanning: test\n",
            "Saved report: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/clean_fix_report.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status\n",
              "keep    1550\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>keep</th>\n",
              "      <td>1550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO caches label/index info under labels/*.cache; delete to refresh after cleaning\n",
        "deleted = []\n",
        "for p in (YOLO_DATA_ROOT/\"labels\").rglob(\"*.cache\"):\n",
        "    deleted.append(str(p))\n",
        "    p.unlink(missing_ok=True)\n",
        "print(\"Deleted caches:\", len(deleted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQ8tuvxWVHl",
        "outputId": "525e03d4-a111-4ca2-b2fa-7816290240ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted caches: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "RUN_NAME = \"y7_tiny_raw_clean\"\n",
        "!python train.py --workers 8 --device 0 --batch-size 16 --img 640 --epochs 50 \\\n",
        "  --data /content/yolov7/data/yoga_raw_clean.yaml --weights yolov7-tiny.pt --name {RUN_NAME}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gem6aAsQWXuy",
        "outputId": "7ba66f14-1948-4164-a520-72e2aca05a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "2025-09-07 22:43:15.426815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757284995.447827   17953 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757284995.454064   17953 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757284995.469709   17953 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757284995.469734   17953 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757284995.469738   17953 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757284995.469741   17953 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-07 22:43:15.474433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "YOLOR üöÄ v0.1-128-ga207844 torch 2.8.0+cu126 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='yolov7-tiny.pt', cfg='', data='/content/yolov7/data/yoga_raw_clean.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=50, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='y7_tiny_raw_clean', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/y7_tiny_raw_clean3', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcolabclearskysoftware\u001b[0m (\u001b[33mcolabclearskysoftware-private\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m creating run (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m creating run (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20250907_224322-9db2jw2p\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33my7_tiny_raw_clean3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/colabclearskysoftware-private/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/colabclearskysoftware-private/YOLOR/runs/9db2jw2p\u001b[0m\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            "  8                -1  1         0  models.common.MP                        []                            \n",
            "  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 15                -1  1         0  models.common.MP                        []                            \n",
            " 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 22                -1  1         0  models.common.MP                        []                            \n",
            " 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 31                -1  1         0  models.common.SP                        [5]                           \n",
            " 32                -2  1         0  models.common.SP                        [9]                           \n",
            " 33                -3  1         0  models.common.SP                        [13]                          \n",
            " 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 36          [-1, -7]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 41          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 59          [-1, 47]  1         0  models.common.Concat                    [1]                           \n",
            " 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 67          [-1, 37]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]                           \n",
            " 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]\n",
            " 77      [74, 75, 76]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 255 layers, 6024826 parameters, 6024826 gradients\n",
            "\n",
            "Transferred 332/338 items from yolov7-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 58 .bias, 58 conv.weight, 55 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/labels/train' images and labels... 862 found, 0 missing, 0 empty, 0 corrupted: 100% 862/862 [00:08<00:00, 104.52it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/labels/val' images and labels... 218 found, 0 missing, 0 empty, 0 corrupted: 100% 218/218 [00:02<00:00, 74.28it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.00, Best Possible Recall (BPR) = 1.0000\n",
            "/content/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=cuda)\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/y7_tiny_raw_clean3\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/54 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
            "/content/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(enabled=cuda):\n",
            "      0/49     2.57G   0.08231   0.04082   0.03747    0.1606        67       640:   7% 4/54 [00:33<04:09,  4.98s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.08046   0.03978     0.036    0.1562        54       640:   9% 5/54 [00:34<02:46,  3.40s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.06983   0.02907   0.03223    0.1311        55       640:  28% 15/54 [00:48<01:06,  1.71s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.06704   0.02461   0.03093    0.1226        71       640:  43% 23/54 [01:00<00:52,  1.68s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.06723   0.02424   0.03124    0.1227        63       640:  44% 24/54 [01:01<00:48,  1.61s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.06553   0.02065   0.03058    0.1168        58       640:  67% 36/54 [01:19<00:25,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49     2.57G   0.06314   0.01846   0.02958    0.1112        49       640:  96% 52/54 [01:45<00:02,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "      0/49    0.679G   0.06289   0.01821   0.02952    0.1106        44       640: 100% 54/54 [02:16<00:00,  2.54s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:07<00:00,  1.10s/it]\n",
            "                 all         218         218      0.0162       0.417      0.0152     0.00612\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     2.58G   0.05637   0.01427   0.02655   0.09718        51       640:  13% 7/54 [00:05<00:44,  1.06it/s]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.05397   0.01378   0.02628   0.09402        48       640:  22% 12/54 [00:12<00:56,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.05464   0.01398   0.02655   0.09517        77       640:  24% 13/54 [00:16<01:18,  1.91s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.05478   0.01386   0.02714   0.09578        54       640:  28% 15/54 [00:18<00:57,  1.47s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.05364   0.01368   0.02748    0.0948        47       640:  48% 26/54 [00:33<00:37,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G    0.0522    0.0136     0.027   0.09281        55       640:  56% 30/54 [00:39<00:29,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.05117   0.01355   0.02652   0.09124        43       640:  74% 40/54 [00:55<00:18,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.04965   0.01335   0.02589    0.0889        55       640:  85% 46/54 [01:05<00:12,  1.52s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.04911   0.01332   0.02541   0.08783        57       640:  93% 50/54 [01:11<00:05,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "      1/49     2.58G   0.04861   0.01333   0.02515   0.08708        53       640: 100% 54/54 [01:17<00:00,  1.43s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.64it/s]\n",
            "                 all         218         218       0.124       0.336       0.111      0.0452\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     3.66G   0.04646   0.01161   0.03257   0.09064        51       640:   2% 1/54 [00:00<00:19,  2.65it/s]Corrupt JPEG data: premature end of data segment\n",
            "      2/49     3.66G    0.0419   0.01253   0.02262   0.07705        47       640:  15% 8/54 [00:10<00:52,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "      2/49     3.66G   0.03853   0.01309   0.02097   0.07259        68       640:  26% 14/54 [00:21<01:02,  1.57s/it]Corrupt JPEG data: premature end of data segment\n",
            "      2/49     3.66G   0.03947   0.01312   0.02118   0.07377        68       640:  57% 31/54 [00:43<00:30,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "      2/49     3.66G   0.04202   0.01309   0.02176   0.07687        50       640:  87% 47/54 [01:06<00:11,  1.60s/it]Corrupt JPEG data: premature end of data segment\n",
            "      2/49     3.66G   0.04267   0.01319   0.02237   0.07822        49       640: 100% 54/54 [01:15<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.28it/s]\n",
            "                 all         218         218       0.196       0.389       0.182       0.124\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     3.66G   0.04408   0.01331   0.02374   0.08113        57       640:  22% 12/54 [00:15<00:51,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "      3/49     3.66G   0.04591   0.01335   0.02467   0.08393        64       640:  26% 14/54 [00:19<00:52,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "      3/49     3.66G   0.04204   0.01278   0.02289   0.07771        54       640:  52% 28/54 [00:38<00:34,  1.33s/it]Corrupt JPEG data: premature end of data segment\n",
            "      3/49     3.66G   0.04129   0.01281   0.02286   0.07696        60       640:  81% 44/54 [01:01<00:12,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "      3/49     3.66G   0.04153   0.01259   0.02282   0.07695        81       640: 100% 54/54 [01:15<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.67it/s]\n",
            "                 all         218         218       0.232       0.584       0.254       0.227\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     3.66G    0.0432   0.01184   0.02296   0.07801        61       640:  15% 8/54 [00:09<00:46,  1.02s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G    0.0438   0.01216   0.02329   0.07926        68       640:  19% 10/54 [00:11<00:47,  1.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.04215   0.01226   0.02303   0.07744        75       640:  24% 13/54 [00:18<01:16,  1.86s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G    0.0414   0.01227   0.02274    0.0764        64       640:  26% 14/54 [00:18<00:58,  1.46s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.04235   0.01197   0.02285   0.07717        54       640:  31% 17/54 [00:22<00:46,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.04059   0.01178   0.02198   0.07435        54       640:  56% 30/54 [00:39<00:25,  1.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.03993   0.01155   0.02243   0.07391        51       640:  81% 44/54 [01:02<00:13,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.03988    0.0116   0.02229   0.07377        65       640:  85% 46/54 [01:05<00:10,  1.33s/it]Corrupt JPEG data: premature end of data segment\n",
            "      4/49     3.66G   0.04031   0.01167    0.0226   0.07458        57       640: 100% 54/54 [01:16<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/7 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "                 all         218         218        0.17       0.536       0.167       0.103\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     3.67G   0.04036   0.01149   0.02038   0.07223        64       640:  17% 9/54 [00:10<01:05,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.03778     0.011   0.01928   0.06806        48       640:  28% 15/54 [00:18<01:01,  1.57s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.03896    0.0111    0.0199   0.06996        61       640:  59% 32/54 [00:41<00:29,  1.33s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.03868   0.01105   0.02022   0.06995        49       640:  65% 35/54 [00:44<00:24,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.03938   0.01107   0.02047   0.07093        61       640:  69% 37/54 [00:48<00:23,  1.39s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.04126   0.01102   0.02112    0.0734        58       640:  80% 43/54 [00:56<00:14,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.04123   0.01113   0.02115   0.07352        63       640:  83% 45/54 [00:59<00:12,  1.44s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G    0.0414   0.01115   0.02116   0.07371        57       640:  87% 47/54 [01:02<00:09,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "      5/49     3.67G   0.04111   0.01115   0.02129   0.07354        42       640: 100% 54/54 [01:11<00:00,  1.32s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "                 all         218         218        0.17       0.611       0.218       0.133\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     3.67G   0.04038   0.01097   0.01963   0.07098        47       640:  13% 7/54 [00:06<00:46,  1.01it/s]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03816   0.01136   0.02023   0.06976        58       640:  28% 15/54 [00:18<00:43,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G    0.0392   0.01177   0.02164   0.07261        67       640:  35% 19/54 [00:24<00:45,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03741   0.01194   0.02109   0.07044        52       640:  54% 29/54 [00:38<00:30,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03731   0.01234   0.02085    0.0705        74       640:  69% 37/54 [00:48<00:18,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03823   0.01228   0.02095   0.07146        49       640:  72% 39/54 [00:52<00:20,  1.36s/it]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03727   0.01231   0.02055   0.07013        66       640:  85% 46/54 [01:02<00:12,  1.61s/it]Corrupt JPEG data: premature end of data segment\n",
            "      6/49     3.67G   0.03781   0.01235   0.02055   0.07071        48       640: 100% 54/54 [01:12<00:00,  1.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.54it/s]\n",
            "                 all         218         218       0.172       0.511        0.19       0.149\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     3.67G    0.0291   0.01314   0.01721   0.05946        55       640:  15% 8/54 [00:10<01:02,  1.36s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03217   0.01301   0.01839   0.06357        65       640:  17% 9/54 [00:11<00:58,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G    0.0338   0.01235   0.01998   0.06614        50       640:  28% 15/54 [00:20<00:57,  1.48s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03368   0.01225   0.02008   0.06601        63       640:  46% 25/54 [00:33<00:39,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03447   0.01237   0.02021   0.06705        51       640:  80% 43/54 [00:59<00:13,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03493   0.01241   0.02029   0.06762        65       640:  91% 49/54 [01:08<00:05,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03606   0.01239   0.02054   0.06899        85       640:  98% 53/54 [01:13<00:01,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "      7/49     3.67G   0.03596   0.01241   0.02051   0.06888        54       640: 100% 54/54 [01:15<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.28it/s]\n",
            "                 all         218         218       0.125         0.6       0.141      0.0585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     3.69G   0.04637   0.01208   0.02479   0.08323        77       640:  17% 9/54 [00:10<01:05,  1.46s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.04196   0.01227   0.02377     0.078        61       640:  28% 15/54 [00:18<00:44,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.04068   0.01225   0.02318   0.07611        56       640:  31% 17/54 [00:21<00:44,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.04007   0.01238   0.02238   0.07483        55       640:  46% 25/54 [00:32<00:37,  1.28s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.03962   0.01258   0.02208   0.07428        55       640:  57% 31/54 [00:41<00:30,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.03769   0.01246   0.02129   0.07144        45       640:  76% 41/54 [00:56<00:19,  1.46s/it]Corrupt JPEG data: premature end of data segment\n",
            "      8/49     3.69G   0.03838   0.01227   0.02131   0.07196        45       640: 100% 54/54 [01:12<00:00,  1.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.65it/s]\n",
            "                 all         218         218       0.181       0.684       0.218       0.137\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49      3.7G     0.031   0.01238   0.02897   0.07235        67       640:   4% 2/54 [00:01<00:34,  1.49it/s]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03159   0.01189   0.02347   0.06695        51       640:   7% 4/54 [00:05<01:05,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03287   0.01191   0.02069   0.06547        48       640:  22% 12/54 [00:15<00:43,  1.04s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03245   0.01177   0.02043   0.06465        50       640:  26% 14/54 [00:19<00:59,  1.48s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03203   0.01174   0.02033    0.0641        50       640:  30% 16/54 [00:23<00:57,  1.50s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03173   0.01194   0.02018   0.06385        53       640:  33% 18/54 [00:25<00:48,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03207   0.01219   0.02001   0.06428        52       640:  39% 21/54 [00:30<00:48,  1.48s/it]Corrupt JPEG data: premature end of data segment\n",
            "      9/49      3.7G   0.03138   0.01198    0.0187   0.06207        52       640: 100% 54/54 [01:18<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  71% 5/7 [00:05<00:01,  1.37it/s]Corrupt JPEG data: premature end of data segment\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:07<00:00,  1.01s/it]\n",
            "                 all         218         218       0.148       0.459       0.141      0.0847\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/54 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.03874   0.01158   0.02038    0.0707        48       640:  11% 6/54 [00:06<00:55,  1.15s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.04057   0.01149   0.01995     0.072        48       640:  19% 10/54 [00:11<00:48,  1.09s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.03788   0.01106   0.01955    0.0685        43       640:  26% 14/54 [00:15<00:41,  1.05s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.04032   0.01125   0.02059   0.07217        51       640:  30% 16/54 [00:19<00:50,  1.32s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.04095   0.01201   0.02128   0.07425        69       640:  44% 24/54 [00:31<00:38,  1.28s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G    0.0405   0.01196   0.02113   0.07359        64       640:  59% 32/54 [00:42<00:26,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.03971   0.01223   0.02122   0.07316        71       640:  83% 45/54 [01:02<00:16,  1.88s/it]Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.03942   0.01224   0.02115    0.0728        55       640:  85% 46/54 [01:03<00:12,  1.55s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     10/49      3.7G   0.03898   0.01221   0.02083   0.07202        49       640: 100% 54/54 [01:12<00:00,  1.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.22it/s]\n",
            "                 all         218         218        0.16       0.578       0.167      0.0957\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49      3.7G   0.04293   0.01145   0.02129   0.07566        54       640:  22% 12/54 [00:13<00:54,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     11/49      3.7G   0.04518   0.01191   0.02221    0.0793        72       640:  26% 14/54 [00:17<00:55,  1.40s/it]Corrupt JPEG data: premature end of data segment\n",
            "     11/49      3.7G   0.03985   0.01174   0.02067   0.07226        44       640:  43% 23/54 [00:29<00:41,  1.32s/it]Corrupt JPEG data: premature end of data segment\n",
            "     11/49      3.7G    0.0382   0.01186   0.01998   0.07005        67       640:  48% 26/54 [00:34<00:41,  1.50s/it]Corrupt JPEG data: premature end of data segment\n",
            "     11/49      3.7G   0.03791    0.0116   0.01964   0.06915        71       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.68it/s]\n",
            "                 all         218         218       0.174       0.794       0.223       0.178\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     3.72G   0.04391   0.01147   0.02396   0.07934        71       640:  11% 6/54 [00:08<01:05,  1.36s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.03593   0.01134   0.02013    0.0674        56       640:  26% 14/54 [00:19<00:50,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.03793   0.01092   0.01978   0.06863        52       640:  33% 18/54 [00:25<00:43,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G    0.0362   0.01082   0.01987   0.06689        58       640:  41% 22/54 [00:30<00:36,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.03732   0.01109   0.01923   0.06765        67       640:  52% 28/54 [00:39<00:33,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.03856   0.01109   0.01951   0.06917        48       640:  56% 30/54 [00:41<00:26,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.03719   0.01119   0.01941   0.06779        64       640:  74% 40/54 [00:56<00:18,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "     12/49     3.72G   0.04191   0.01148   0.02072   0.07411        47       640: 100% 54/54 [01:16<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.21it/s]\n",
            "                 all         218         218       0.163       0.587       0.168       0.124\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     3.72G   0.04211   0.01265   0.02386   0.07862        51       640:  28% 15/54 [00:19<00:50,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     13/49     3.72G   0.04143    0.0121   0.02267    0.0762        54       640:  59% 32/54 [00:42<00:24,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "     13/49     3.72G   0.04144   0.01211   0.02329   0.07684        54       640:  63% 34/54 [00:45<00:23,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "     13/49     3.72G   0.04281   0.01218    0.0234    0.0784        60       640:  78% 42/54 [00:57<00:16,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "     13/49     3.72G   0.04367   0.01213   0.02338   0.07918        56       640:  83% 45/54 [01:01<00:12,  1.39s/it]Corrupt JPEG data: premature end of data segment\n",
            "     13/49     3.72G   0.04278   0.01212   0.02268   0.07758        50       640: 100% 54/54 [01:14<00:00,  1.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.58it/s]\n",
            "                 all         218         218       0.193       0.674       0.211        0.17\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     3.72G   0.05666   0.01217   0.02289   0.09172        53       640:  15% 8/54 [00:11<01:22,  1.79s/it]Corrupt JPEG data: premature end of data segment\n",
            "     14/49     3.72G   0.04769   0.01236   0.02258   0.08264        70       640:  28% 15/54 [00:23<00:55,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "     14/49     3.72G   0.04698   0.01201   0.02198   0.08097        70       640:  39% 21/54 [00:32<00:50,  1.53s/it]Corrupt JPEG data: premature end of data segment\n",
            "     14/49     3.72G   0.04542   0.01162   0.02188   0.07892        63       640:  50% 27/54 [00:38<00:28,  1.05s/it]Corrupt JPEG data: premature end of data segment\n",
            "     14/49     3.72G   0.04363   0.01185   0.02177   0.07725        52       640: 100% 54/54 [01:16<00:00,  1.42s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:06<00:00,  1.06it/s]\n",
            "                 all         218         218       0.184       0.656       0.225       0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     3.72G   0.03305   0.01125   0.01925   0.06355        42       640:  13% 7/54 [00:07<00:57,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.03159   0.01095   0.01845   0.06099        49       640:  24% 13/54 [00:13<00:46,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.03333   0.01112   0.01878   0.06323        61       640:  28% 15/54 [00:16<00:48,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.03873   0.01181   0.02064   0.07119        79       640:  61% 33/54 [00:43<00:23,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.03844   0.01186   0.02064   0.07094        60       640:  63% 34/54 [00:48<00:41,  2.06s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G    0.0384   0.01181    0.0206   0.07081        61       640:  65% 35/54 [00:48<00:30,  1.63s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.03931   0.01187   0.02063    0.0718        56       640:  83% 45/54 [01:01<00:12,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G    0.0392     0.012   0.02073   0.07193        55       640:  91% 49/54 [01:07<00:06,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.04018     0.012   0.02137   0.07355        60       640:  94% 51/54 [01:10<00:03,  1.21s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     15/49     3.72G   0.04022   0.01203   0.02137   0.07362        59       640: 100% 54/54 [01:16<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.68it/s]\n",
            "                 all         218         218       0.212       0.696       0.255       0.244\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     3.72G   0.05057   0.01651   0.02006   0.08715        78       640:   4% 2/54 [00:01<00:32,  1.62it/s]Corrupt JPEG data: premature end of data segment\n",
            "     16/49     3.72G   0.03648   0.01198     0.019   0.06746        63       640:  28% 15/54 [00:17<00:43,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "     16/49     3.72G   0.03717   0.01187   0.01962   0.06865        57       640:  83% 45/54 [01:00<00:11,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "     16/49     3.72G    0.0377   0.01168   0.01968   0.06906        41       640: 100% 54/54 [01:14<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.92it/s]\n",
            "                 all         218         218       0.195       0.606         0.2       0.167\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     3.72G   0.02741   0.01248   0.01682   0.05671        59       640:   9% 5/54 [00:06<00:58,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.02891   0.01241   0.02015   0.06146        53       640:  30% 16/54 [00:22<00:59,  1.57s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.03261   0.01225   0.02026   0.06512        55       640:  46% 25/54 [00:35<00:37,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.03274   0.01214   0.02012     0.065        59       640:  72% 39/54 [00:54<00:18,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.03288   0.01216   0.02002   0.06506        50       640:  76% 41/54 [00:56<00:14,  1.09s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.03329   0.01222   0.02001   0.06552        59       640:  81% 44/54 [01:01<00:14,  1.50s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G    0.0334   0.01228   0.01999   0.06566        72       640:  83% 45/54 [01:03<00:13,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G   0.03316   0.01212    0.0195   0.06477        62       640:  94% 51/54 [01:10<00:03,  1.16s/it]Corrupt JPEG data: premature end of data segment\n",
            "     17/49     3.72G    0.0327   0.01204   0.01925   0.06398        55       640: 100% 54/54 [01:14<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.27it/s]\n",
            "                 all         218         218        0.12       0.293       0.101      0.0363\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     3.72G   0.03444   0.01216   0.01856   0.06516        56       640:  28% 15/54 [00:18<00:46,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "     18/49     3.72G   0.03959   0.01235   0.02079   0.07273        49       640: 100% 54/54 [01:15<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.46it/s]\n",
            "                 all         218         218       0.167       0.583       0.204        0.13\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     3.72G   0.04059    0.0133   0.02317   0.07706        54       640:   4% 2/54 [00:01<00:34,  1.49it/s]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G   0.04439   0.01278   0.02183     0.079        78       640:   7% 4/54 [00:05<01:10,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G   0.04274   0.01281   0.02149   0.07703        59       640:   9% 5/54 [00:06<01:06,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G   0.04316   0.01243   0.01943   0.07501        68       640:  28% 15/54 [00:20<00:53,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G    0.0402   0.01275   0.01851   0.07146        52       640:  50% 27/54 [00:38<00:28,  1.05s/it]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G   0.04318   0.01257   0.01936   0.07511        60       640:  87% 47/54 [01:06<00:08,  1.18s/it]Corrupt JPEG data: premature end of data segment\n",
            "     19/49     3.72G   0.04395   0.01261   0.01958   0.07614        51       640: 100% 54/54 [01:18<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:06<00:00,  1.13it/s]\n",
            "                 all         218         218       0.506       0.255       0.122      0.0366\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     3.72G   0.04164   0.01179   0.01845   0.07187        57       640:  24% 13/54 [00:15<01:01,  1.51s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04199   0.01191   0.01859   0.07249        66       640:  28% 15/54 [00:18<00:56,  1.46s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04204   0.01199   0.01878   0.07281        45       640:  39% 21/54 [00:25<00:36,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04007   0.01213   0.01796   0.07016        61       640:  52% 28/54 [00:35<00:34,  1.32s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04358   0.01245   0.01979   0.07582        61       640:  85% 46/54 [00:59<00:13,  1.67s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04268   0.01246   0.02034   0.07548        54       640:  96% 52/54 [01:06<00:02,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "     20/49     3.72G   0.04347   0.01252   0.02043   0.07642        53       640: 100% 54/54 [01:08<00:00,  1.27s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.23it/s]\n",
            "                 all         218         218      0.0933       0.221      0.0431      0.0119\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     3.72G   0.03902   0.01332   0.02288   0.07522        40       640:  28% 15/54 [00:21<00:59,  1.53s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     21/49     3.72G   0.03695   0.01296   0.01987   0.06978        68       640:  57% 31/54 [00:44<00:28,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "     21/49     3.72G   0.03998   0.01271   0.02018   0.07288        49       640:  98% 53/54 [01:15<00:01,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     21/49     3.72G   0.04011   0.01276   0.02053    0.0734        60       640: 100% 54/54 [01:16<00:00,  1.43s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.73it/s]\n",
            "                 all         218         218      0.0912       0.515       0.105      0.0511\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     3.72G   0.04181   0.01284   0.02076   0.07542        39       640:   6% 3/54 [00:02<00:48,  1.06it/s]Corrupt JPEG data: premature end of data segment\n",
            "     22/49     3.72G   0.03038   0.01454   0.01638    0.0613        58       640:  28% 15/54 [00:21<01:06,  1.72s/it]Corrupt JPEG data: premature end of data segment\n",
            "     22/49     3.72G   0.03159   0.01434   0.01674   0.06267        49       640:  30% 16/54 [00:22<00:53,  1.40s/it]Corrupt JPEG data: premature end of data segment\n",
            "     22/49     3.72G   0.03031     0.014   0.01639    0.0607        51       640:  33% 18/54 [00:24<00:43,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     22/49     3.72G   0.03274   0.01389   0.01873   0.06536        68       640:  54% 29/54 [00:39<00:32,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     22/49     3.72G   0.03453   0.01357   0.01969   0.06779        43       640: 100% 54/54 [01:14<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.65it/s]\n",
            "                 all         218         218        0.03       0.371      0.0262     0.00546\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     3.72G   0.02889   0.01348   0.01828   0.06064        68       640:  20% 11/54 [00:13<00:48,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "     23/49     3.72G   0.03246   0.01342   0.01858   0.06446        64       640:  28% 15/54 [00:18<00:48,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     23/49     3.72G   0.02961    0.0131   0.01759   0.06031        36       640:  33% 18/54 [00:23<00:58,  1.62s/it]Corrupt JPEG data: premature end of data segment\n",
            "     23/49     3.72G   0.03154   0.01363   0.01802   0.06319        50       640:  67% 36/54 [00:47<00:22,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     23/49     3.72G   0.03226   0.01361    0.0177   0.06357        51       640:  74% 40/54 [00:57<00:24,  1.78s/it]Corrupt JPEG data: premature end of data segment\n",
            "     23/49     3.72G   0.03551   0.01362   0.01922   0.06835        49       640: 100% 54/54 [01:21<00:00,  1.52s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.53it/s]\n",
            "                 all         218         218      0.0752       0.173      0.0551      0.0225\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     3.72G   0.06064   0.01297   0.02606   0.09967        52       640:   9% 5/54 [00:05<01:01,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.04527   0.01374   0.02301   0.08201        66       640:  22% 12/54 [00:13<00:45,  1.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.04291   0.01376    0.0226   0.07926        55       640:  26% 14/54 [00:16<00:43,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.04045   0.01359   0.02126   0.07529        65       640:  52% 28/54 [00:38<00:47,  1.82s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.04047   0.01365   0.02117   0.07529        68       640:  54% 29/54 [00:39<00:41,  1.66s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.04021   0.01313   0.02053   0.07388        51       640:  93% 50/54 [01:09<00:05,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     24/49     3.72G   0.03966   0.01322   0.02034   0.07322        50       640: 100% 54/54 [01:14<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:08<00:00,  1.22s/it]\n",
            "                 all         218         218      0.0593       0.176      0.0394      0.0142\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     3.72G   0.02881   0.01336   0.01648   0.05864        50       640:  26% 14/54 [00:17<00:49,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03249   0.01355   0.01679   0.06284        73       640:  41% 22/54 [00:29<00:49,  1.56s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03392   0.01343    0.0172   0.06456        52       640:  52% 28/54 [00:36<00:31,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03523   0.01342   0.01813   0.06678        56       640:  56% 30/54 [00:40<00:35,  1.47s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03433    0.0134   0.01782   0.06555        57       640:  59% 32/54 [00:43<00:31,  1.44s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03411   0.01355     0.018   0.06565        57       640:  67% 36/54 [00:49<00:21,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03408   0.01357   0.01799   0.06564        69       640:  69% 37/54 [00:51<00:25,  1.51s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03383   0.01369   0.01766   0.06518        68       640:  81% 44/54 [01:00<00:11,  1.12s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03371   0.01368   0.01769   0.06508        63       640:  85% 46/54 [01:03<00:10,  1.28s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03342   0.01365   0.01766   0.06474        51       640:  87% 47/54 [01:05<00:10,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03353   0.01365   0.01771   0.06489        66       640:  89% 48/54 [01:06<00:06,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "     25/49     3.72G   0.03294   0.01351    0.0173   0.06374        59       640: 100% 54/54 [01:14<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.83it/s]\n",
            "                 all         218         218      0.0328        0.21      0.0257     0.00998\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     3.72G   0.02534   0.01242   0.01592   0.05368        40       640:   7% 4/54 [00:04<01:00,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03473   0.01235   0.01804   0.06512        47       640:  13% 7/54 [00:09<01:05,  1.39s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03913   0.01277   0.01827   0.07017        57       640:  28% 15/54 [00:19<00:51,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03927   0.01324   0.01822   0.07073        64       640:  35% 19/54 [00:25<00:44,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03961   0.01331   0.01848   0.07139        62       640:  39% 21/54 [00:27<00:37,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03487   0.01325   0.01815   0.06627        81       640:  67% 36/54 [00:48<00:29,  1.66s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03714    0.0132   0.01919   0.06952        54       640:  85% 46/54 [01:02<00:11,  1.49s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03667   0.01319    0.0192   0.06905        57       640:  87% 47/54 [01:05<00:12,  1.81s/it]Corrupt JPEG data: premature end of data segment\n",
            "     26/49     3.72G   0.03607   0.01328   0.01914    0.0685        64       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.19it/s]\n",
            "                 all         218         218      0.0757       0.305      0.0641      0.0277\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     3.72G   0.03095   0.01354   0.02026   0.06474        57       640:   7% 4/54 [00:03<00:47,  1.04it/s]Corrupt JPEG data: premature end of data segment\n",
            "     27/49     3.72G   0.03038   0.01354   0.01859   0.06251        58       640:  19% 10/54 [00:13<01:15,  1.72s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     27/49     3.72G   0.03274   0.01353   0.01921   0.06549        56       640:  28% 15/54 [00:19<00:49,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "     27/49     3.72G      0.03   0.01338   0.01801   0.06139        76       640:  80% 43/54 [01:00<00:13,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     27/49     3.72G   0.02917   0.01332   0.01721    0.0597        44       640: 100% 54/54 [01:15<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.67it/s]\n",
            "                 all         218         218      0.0645       0.335      0.0495      0.0292\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     3.72G   0.03142   0.01413   0.01894   0.06449        78       640:  28% 15/54 [00:23<00:59,  1.54s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G   0.03221   0.01417    0.0189   0.06527        68       640:  30% 16/54 [00:25<01:11,  1.87s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G   0.03045   0.01374   0.01838   0.06257        60       640:  37% 20/54 [00:33<01:10,  2.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G    0.0285   0.01358    0.0176   0.05968        57       640:  54% 29/54 [00:46<00:43,  1.75s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G   0.02604   0.01363   0.01725   0.05693        72       640:  78% 42/54 [01:05<00:16,  1.39s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G   0.02629   0.01353   0.01751   0.05733        45       640:  81% 44/54 [01:07<00:11,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G    0.0262   0.01359   0.01755   0.05733        76       640:  93% 50/54 [01:16<00:05,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "     28/49     3.72G    0.0257   0.01353   0.01746    0.0567        45       640: 100% 54/54 [01:22<00:00,  1.52s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.38it/s]\n",
            "                 all         218         218       0.147        0.51       0.148      0.0892\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     3.72G   0.02075   0.01413   0.01587   0.05076        60       640:  11% 6/54 [00:04<00:38,  1.26it/s]Corrupt JPEG data: premature end of data segment\n",
            "     29/49     3.72G   0.02586   0.01357   0.01759   0.05702        48       640:  28% 15/54 [00:17<00:51,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "     29/49     3.72G   0.02603   0.01331   0.01727   0.05661        50       640:  65% 35/54 [00:46<00:27,  1.44s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     29/49     3.72G   0.02593   0.01347   0.01701   0.05641        42       640: 100% 54/54 [01:10<00:00,  1.30s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:09<00:00,  1.36s/it]\n",
            "                 all         218         218       0.176       0.504       0.165      0.0977\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     3.72G    0.0235   0.01306   0.01712   0.05368        52       640:  28% 15/54 [00:17<00:50,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "     30/49     3.72G   0.02326   0.01339   0.01745    0.0541        56       640:  33% 18/54 [00:20<00:40,  1.12s/it]Corrupt JPEG data: premature end of data segment\n",
            "     30/49     3.72G   0.02308   0.01341    0.0172   0.05368        68       640:  43% 23/54 [00:28<00:45,  1.47s/it]Corrupt JPEG data: premature end of data segment\n",
            "     30/49     3.72G   0.02301   0.01305   0.01703   0.05309        67       640:  56% 30/54 [00:37<00:35,  1.48s/it]Corrupt JPEG data: premature end of data segment\n",
            "     30/49     3.72G     0.026   0.01337   0.01704    0.0564        47       640: 100% 54/54 [01:14<00:00,  1.38s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.42it/s]\n",
            "                 all         218         218       0.142       0.555       0.151      0.0961\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     3.72G   0.02864   0.01417   0.01573   0.05854        58       640:  30% 16/54 [00:20<00:43,  1.15s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G   0.02802   0.01408   0.01505   0.05715        51       640:  35% 19/54 [00:24<00:45,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G   0.02711   0.01411   0.01477   0.05599        47       640:  37% 20/54 [00:25<00:39,  1.17s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G   0.02649   0.01341   0.01592   0.05583        49       640:  56% 30/54 [00:38<00:26,  1.12s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G   0.02541   0.01361   0.01659   0.05561        47       640:  81% 44/54 [01:01<00:15,  1.53s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G    0.0254   0.01364   0.01694   0.05599        56       640:  96% 52/54 [01:12<00:02,  1.33s/it]Corrupt JPEG data: premature end of data segment\n",
            "     31/49     3.72G   0.02482   0.01357   0.01665   0.05504        40       640: 100% 54/54 [01:15<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.52it/s]\n",
            "                 all         218         218       0.139       0.579       0.151       0.101\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     3.72G   0.01231   0.01377   0.01123   0.03731        52       640:  11% 6/54 [00:06<00:58,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02267   0.01378    0.0145   0.05094        63       640:  28% 15/54 [00:17<00:44,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02111   0.01394   0.01392   0.04897        53       640:  31% 17/54 [00:21<00:52,  1.41s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02518   0.01368   0.01493   0.05379        49       640:  54% 29/54 [00:38<00:31,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02579   0.01372   0.01539    0.0549        58       640:  87% 47/54 [01:04<00:10,  1.44s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02604   0.01368   0.01556   0.05528        60       640:  91% 49/54 [01:07<00:07,  1.52s/it]Corrupt JPEG data: premature end of data segment\n",
            "     32/49     3.72G   0.02664   0.01375   0.01588   0.05628        72       640: 100% 54/54 [01:15<00:00,  1.41s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.18it/s]\n",
            "                 all         218         218       0.171       0.491       0.188       0.135\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49     3.72G   0.02539   0.01386   0.01579   0.05504        51       640:  22% 12/54 [00:15<00:57,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G   0.02319   0.01372    0.0149   0.05181        51       640:  26% 14/54 [00:17<00:47,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G   0.02177   0.01342   0.01535   0.05054        57       640:  37% 20/54 [00:26<00:48,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G    0.0229   0.01328   0.01594   0.05212        58       640:  56% 30/54 [00:39<00:29,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G   0.02442    0.0133   0.01639   0.05411        45       640:  76% 41/54 [00:56<00:20,  1.60s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G   0.02445   0.01336   0.01648   0.05429        67       640:  78% 42/54 [00:56<00:15,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G    0.0245   0.01361   0.01636   0.05447        51       640:  93% 50/54 [01:07<00:04,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G    0.0247   0.01365   0.01641   0.05476        46       640:  98% 53/54 [01:13<00:01,  1.47s/it]Corrupt JPEG data: premature end of data segment\n",
            "     33/49     3.72G   0.02472   0.01364   0.01643   0.05479        44       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  29% 2/7 [00:00<00:02,  2.12it/s]Corrupt JPEG data: premature end of data segment\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.35it/s]\n",
            "                 all         218         218       0.132       0.671       0.157       0.121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49     3.72G   0.02512   0.01292   0.01655    0.0546        49       640:  26% 14/54 [00:17<00:50,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02499   0.01321   0.01625   0.05445        56       640:  52% 28/54 [00:36<00:33,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02486   0.01322   0.01601   0.05408        51       640:  63% 34/54 [00:44<00:21,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02469   0.01329   0.01607   0.05405        58       640:  78% 42/54 [00:56<00:14,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02621   0.01337   0.01628   0.05586        57       640:  89% 48/54 [01:05<00:07,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02635   0.01338   0.01633   0.05606        70       640:  91% 49/54 [01:07<00:07,  1.59s/it]Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G   0.02643   0.01335   0.01627   0.05605        61       640:  96% 52/54 [01:10<00:02,  1.21s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     34/49     3.72G    0.0266   0.01335   0.01637   0.05632        53       640: 100% 54/54 [01:12<00:00,  1.34s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:09<00:00,  1.36s/it]\n",
            "                 all         218         218      0.0792       0.476      0.0865      0.0571\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49     3.72G   0.02255   0.01298   0.01772   0.05325        54       640:  19% 10/54 [00:10<00:55,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02341   0.01244   0.01795   0.05381        42       640:  26% 14/54 [00:14<00:41,  1.03s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02377   0.01302   0.01846   0.05526        57       640:  31% 17/54 [00:19<00:53,  1.44s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02436   0.01333   0.01849   0.05618        74       640:  41% 22/54 [00:27<00:45,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02627   0.01311   0.01855   0.05794        55       640:  50% 27/54 [00:34<00:34,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02844   0.01346   0.01864   0.06054        60       640:  72% 39/54 [00:54<00:20,  1.34s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02885   0.01326   0.01851   0.06062        68       640:  98% 53/54 [01:14<00:01,  1.21s/it]Corrupt JPEG data: premature end of data segment\n",
            "     35/49     3.72G   0.02854   0.01329   0.01833   0.06016        54       640: 100% 54/54 [01:15<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:07<00:00,  1.00s/it]\n",
            "                 all         218         218       0.113       0.468       0.123      0.0733\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49     3.72G   0.03264   0.01362   0.01872   0.06498        54       640:  28% 15/54 [00:18<00:48,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "     36/49     3.72G   0.03025    0.0141   0.01778   0.06213        71       640:  37% 20/54 [00:25<00:52,  1.53s/it]Corrupt JPEG data: premature end of data segment\n",
            "     36/49     3.72G   0.02968   0.01395   0.01794   0.06157        57       640:  54% 29/54 [00:38<00:35,  1.41s/it]Corrupt JPEG data: premature end of data segment\n",
            "     36/49     3.72G   0.02961   0.01387   0.01763   0.06111        53       640:  80% 43/54 [00:58<00:14,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     36/49     3.72G   0.02986   0.01398   0.01755   0.06139        51       640: 100% 54/54 [01:14<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.79it/s]\n",
            "                 all         218         218      0.0986       0.538       0.102      0.0612\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49     3.72G   0.02461     0.014   0.01668   0.05529        53       640:  28% 15/54 [00:20<01:08,  1.74s/it]Corrupt JPEG data: premature end of data segment\n",
            "     37/49     3.72G   0.02537   0.01407   0.01677   0.05621        59       640:  30% 16/54 [00:20<00:53,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     37/49     3.72G   0.02661   0.01404   0.01719   0.05785        72       640:  37% 20/54 [00:25<00:40,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "     37/49     3.72G   0.02762   0.01404    0.0169   0.05855        54       640:  61% 33/54 [00:43<00:24,  1.18s/it]Corrupt JPEG data: premature end of data segment\n",
            "     37/49     3.72G   0.02641     0.014    0.0172   0.05761        51       640: 100% 54/54 [01:20<00:00,  1.49s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.87it/s]\n",
            "                 all         218         218       0.112       0.472       0.125      0.0836\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49     3.72G   0.01993    0.0159   0.01398   0.04981        73       640:  15% 8/54 [00:10<01:16,  1.66s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02147   0.01491   0.01545   0.05183        61       640:  28% 15/54 [00:19<00:48,  1.24s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02467    0.0143   0.01636   0.05533        48       640:  35% 19/54 [00:25<00:44,  1.27s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02388   0.01419   0.01602   0.05409        45       640:  37% 20/54 [00:26<00:42,  1.26s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02427   0.01439   0.01611   0.05477        75       640:  39% 21/54 [00:27<00:34,  1.04s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G    0.0242     0.014   0.01672   0.05491        62       640:  72% 39/54 [00:51<00:19,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02412   0.01385   0.01689   0.05485        47       640:  87% 47/54 [01:01<00:07,  1.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02435   0.01381   0.01699   0.05514        60       640:  93% 50/54 [01:07<00:06,  1.75s/it]Corrupt JPEG data: premature end of data segment\n",
            "     38/49     3.72G   0.02501   0.01384   0.01708   0.05593        41       640: 100% 54/54 [01:13<00:00,  1.35s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.49it/s]\n",
            "                 all         218         218       0.153       0.547       0.159       0.119\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49     3.72G   0.02991   0.01434   0.01847   0.06272        55       640:  24% 13/54 [00:17<01:18,  1.91s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02985   0.01424   0.01855   0.06264        54       640:  26% 14/54 [00:18<00:59,  1.49s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02734   0.01389   0.01841   0.05964        58       640:  37% 20/54 [00:25<00:36,  1.07s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02775   0.01383   0.01776   0.05934        53       640:  59% 32/54 [00:41<00:23,  1.09s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02741   0.01398   0.01785   0.05924        58       640:  67% 36/54 [00:47<00:22,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G    0.0267   0.01405   0.01785    0.0586        55       640:  78% 42/54 [00:55<00:14,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02707   0.01397   0.01804   0.05908        62       640:  89% 48/54 [01:05<00:09,  1.59s/it]Corrupt JPEG data: premature end of data segment\n",
            "     39/49     3.72G   0.02748    0.0139   0.01814   0.05952        55       640: 100% 54/54 [01:13<00:00,  1.37s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/7 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.20it/s]\n",
            "                 all         218         218       0.129       0.727       0.163       0.108\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49     3.72G   0.02434   0.01343   0.01662   0.05439        74       640:  24% 13/54 [00:15<00:56,  1.38s/it]Corrupt JPEG data: premature end of data segment\n",
            "     40/49     3.72G   0.02452   0.01355   0.01667   0.05474        60       640:  26% 14/54 [00:17<00:56,  1.41s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     40/49     3.72G   0.02508   0.01398   0.01707   0.05613        64       640:  69% 37/54 [00:52<00:26,  1.55s/it]Corrupt JPEG data: premature end of data segment\n",
            "     40/49     3.72G   0.02539   0.01404   0.01736   0.05679        62       640:  81% 44/54 [01:03<00:17,  1.72s/it]Corrupt JPEG data: premature end of data segment\n",
            "     40/49     3.72G   0.02542   0.01407   0.01734   0.05683        62       640:  93% 50/54 [01:11<00:05,  1.32s/it]Corrupt JPEG data: premature end of data segment\n",
            "     40/49     3.72G   0.02492   0.01406   0.01724   0.05622        43       640: 100% 54/54 [01:18<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.63it/s]\n",
            "                 all         218         218       0.141       0.477       0.161       0.114\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49     3.72G   0.02656   0.01525    0.0174   0.05921        65       640:  15% 8/54 [00:10<01:06,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02691   0.01531   0.01777   0.05999        50       640:  28% 15/54 [00:19<00:47,  1.21s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02687   0.01467    0.0175   0.05904        54       640:  46% 25/54 [00:32<00:32,  1.12s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02442   0.01423   0.01657   0.05522        49       640:  59% 32/54 [00:42<00:26,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02457   0.01391   0.01688   0.05536        53       640:  83% 45/54 [01:00<00:12,  1.34s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02401   0.01389   0.01669   0.05458        43       640:  87% 47/54 [01:02<00:08,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02398   0.01382   0.01683   0.05462        56       640:  94% 51/54 [01:09<00:04,  1.60s/it]Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02424   0.01382   0.01687   0.05493        56       640:  98% 53/54 [01:11<00:01,  1.31s/it]Corrupt JPEG data: premature end of data segment\n",
            "Corrupt JPEG data: premature end of data segment\n",
            "     41/49     3.72G   0.02419   0.01388   0.01689   0.05496        60       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.79it/s]\n",
            "                 all         218         218       0.192       0.588       0.206       0.152\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49     3.72G   0.02858   0.01156   0.01787   0.05802        59       640:   2% 1/54 [00:00<00:44,  1.19it/s]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G   0.02041   0.01373   0.01617    0.0503        66       640:  15% 8/54 [00:10<00:56,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G   0.02027   0.01398   0.01599   0.05024        76       640:  28% 15/54 [00:20<00:55,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G   0.02249   0.01372   0.01618   0.05239        41       640:  46% 25/54 [00:35<00:43,  1.50s/it]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G   0.02206   0.01367   0.01608   0.05181        66       640:  87% 47/54 [01:08<00:07,  1.06s/it]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G    0.0224   0.01359   0.01614   0.05213        57       640:  96% 52/54 [01:17<00:03,  1.73s/it]Corrupt JPEG data: premature end of data segment\n",
            "     42/49     3.72G   0.02253   0.01361   0.01623   0.05237        53       640: 100% 54/54 [01:19<00:00,  1.47s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  2.16it/s]\n",
            "                 all         218         218       0.161       0.596       0.188       0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49     3.72G   0.03156   0.01389   0.01775   0.06321        56       640:  28% 15/54 [00:21<01:01,  1.58s/it]Corrupt JPEG data: premature end of data segment\n",
            "     43/49     3.72G   0.03165   0.01381   0.01806   0.06352        67       640:  43% 23/54 [00:31<00:33,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "     43/49     3.72G   0.03037   0.01366   0.01809   0.06212        53       640:  50% 27/54 [00:37<00:37,  1.39s/it]Corrupt JPEG data: premature end of data segment\n",
            "     43/49     3.72G    0.0298   0.01369   0.01821   0.06171        61       640:  69% 37/54 [00:51<00:24,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "     43/49     3.72G   0.02904   0.01365   0.01773   0.06042        50       640:  83% 45/54 [01:01<00:09,  1.05s/it]Corrupt JPEG data: premature end of data segment\n",
            "     43/49     3.72G   0.02824    0.0137   0.01779   0.05973        51       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.51it/s]\n",
            "                 all         218         218       0.167       0.671       0.196       0.149\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49     3.72G   0.02426   0.01365   0.01707   0.05498        44       640:  13% 7/54 [00:07<00:48,  1.04s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G   0.02545   0.01358   0.01721   0.05625        38       640:  28% 15/54 [00:18<00:46,  1.20s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G   0.02648   0.01338   0.01718   0.05705        58       640:  50% 27/54 [00:34<00:32,  1.21s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G    0.0261   0.01334   0.01725   0.05668        50       640:  65% 35/54 [00:45<00:21,  1.16s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G   0.02526   0.01338   0.01755    0.0562        61       640:  83% 45/54 [01:00<00:11,  1.30s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G   0.02546    0.0134    0.0176   0.05646        57       640:  87% 47/54 [01:02<00:08,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G   0.02547   0.01366   0.01752   0.05665        80       640:  98% 53/54 [01:13<00:01,  1.82s/it]Corrupt JPEG data: premature end of data segment\n",
            "     44/49     3.72G    0.0257   0.01368   0.01755   0.05693        57       640: 100% 54/54 [01:15<00:00,  1.40s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:07<00:00,  1.07s/it]\n",
            "                 all         218         218       0.187       0.526       0.198       0.153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/54 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G   0.02254   0.01366   0.01732   0.05352        52       640:  26% 14/54 [00:17<01:01,  1.53s/it]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G   0.02726    0.0138   0.01787   0.05892        76       640:  44% 24/54 [00:32<00:47,  1.58s/it]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G   0.02735   0.01416   0.01789    0.0594        79       640:  48% 26/54 [00:35<00:39,  1.41s/it]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G   0.02816   0.01393   0.01789   0.05998        54       640:  59% 32/54 [00:44<00:36,  1.65s/it]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G   0.02807   0.01398   0.01799   0.06004        70       640:  69% 37/54 [00:50<00:23,  1.38s/it]Corrupt JPEG data: premature end of data segment\n",
            "     45/49     3.72G     0.027   0.01362   0.01821   0.05882        55       640: 100% 54/54 [01:15<00:00,  1.39s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.77it/s]\n",
            "                 all         218         218       0.155       0.609       0.187       0.146\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49     3.72G   0.03426   0.01207   0.01751   0.06384        58       640:   7% 4/54 [00:04<01:03,  1.28s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.03019   0.01258   0.01817   0.06094        46       640:  15% 8/54 [00:10<00:57,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02976   0.01278   0.01844   0.06097        46       640:  26% 14/54 [00:19<00:57,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.03078   0.01283   0.01847   0.06209        67       640:  28% 15/54 [00:21<01:03,  1.64s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.03025   0.01305   0.01792   0.06122        70       640:  37% 20/54 [00:28<00:52,  1.54s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02972    0.0133   0.01756   0.06059        63       640:  43% 23/54 [00:32<00:42,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02871   0.01334   0.01722   0.05927        56       640:  46% 25/54 [00:36<00:42,  1.47s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02892   0.01332   0.01725   0.05949        55       640:  48% 26/54 [00:38<00:46,  1.66s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G    0.0288   0.01328   0.01724   0.05931        53       640:  50% 27/54 [00:38<00:37,  1.40s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02839    0.0133   0.01752   0.05921        52       640:  59% 32/54 [00:44<00:26,  1.19s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02803   0.01339   0.01779   0.05921        58       640:  81% 44/54 [01:04<00:15,  1.57s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G   0.02762   0.01355   0.01786   0.05902        73       640:  89% 48/54 [01:09<00:07,  1.17s/it]Corrupt JPEG data: premature end of data segment\n",
            "     46/49     3.72G    0.0283   0.01363   0.01791   0.05984        62       640: 100% 54/54 [01:18<00:00,  1.45s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.37it/s]\n",
            "                 all         218         218       0.168       0.629       0.217       0.171\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49     3.72G   0.03035   0.01291   0.01727   0.06054        56       640:  15% 8/54 [00:08<00:53,  1.17s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G   0.02604   0.01257   0.01735   0.05596        59       640:  28% 15/54 [00:19<00:55,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G   0.02546   0.01341   0.01699   0.05586        68       640:  43% 23/54 [00:33<00:42,  1.37s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G    0.0254   0.01334   0.01703   0.05577        48       640:  46% 25/54 [00:36<00:39,  1.35s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G    0.0261   0.01357   0.01728   0.05695        75       640:  61% 33/54 [00:47<00:24,  1.14s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G   0.02647   0.01355   0.01754   0.05756        47       640:  72% 39/54 [00:56<00:18,  1.23s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G   0.02654   0.01369   0.01771   0.05794        61       640:  83% 45/54 [01:04<00:13,  1.45s/it]Corrupt JPEG data: premature end of data segment\n",
            "     47/49     3.72G   0.02518   0.01354   0.01731   0.05602        38       640: 100% 54/54 [01:17<00:00,  1.44s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "                 all         218         218       0.185        0.56       0.225       0.175\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49     3.72G   0.03809   0.01281   0.01889   0.06979        69       640:  11% 6/54 [00:05<00:49,  1.02s/it]Corrupt JPEG data: premature end of data segment\n",
            "     48/49     3.72G   0.03201   0.01295   0.01875   0.06371        55       640:  26% 14/54 [00:16<00:48,  1.22s/it]Corrupt JPEG data: premature end of data segment\n",
            "     48/49     3.72G   0.03154   0.01271   0.01881   0.06307        54       640:  33% 18/54 [00:21<00:42,  1.17s/it]Corrupt JPEG data: premature end of data segment\n",
            "     48/49     3.72G   0.02982   0.01308   0.01834   0.06124        46       640:  50% 27/54 [00:35<00:38,  1.43s/it]Corrupt JPEG data: premature end of data segment\n",
            "     48/49     3.72G   0.02758   0.01311   0.01777   0.05847        55       640:  59% 32/54 [00:41<00:27,  1.25s/it]Corrupt JPEG data: premature end of data segment\n",
            "     48/49     3.72G   0.02573   0.01331   0.01731   0.05634        63       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.55it/s]\n",
            "                 all         218         218       0.214       0.515       0.247       0.203\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49     3.72G   0.03163   0.01286   0.01775   0.06224        51       640:  22% 12/54 [00:15<00:54,  1.29s/it]Corrupt JPEG data: premature end of data segment\n",
            "     49/49     3.72G   0.03094    0.0131     0.018   0.06204        46       640:  28% 15/54 [00:19<00:55,  1.42s/it]Corrupt JPEG data: premature end of data segment\n",
            "     49/49     3.72G    0.0297   0.01313   0.01817     0.061        54       640:  30% 16/54 [00:21<00:59,  1.56s/it]Corrupt JPEG data: premature end of data segment\n",
            "     49/49     3.72G   0.02915   0.01335   0.01826   0.06077        66       640:  37% 20/54 [00:27<00:51,  1.51s/it]Corrupt JPEG data: premature end of data segment\n",
            "     49/49     3.72G   0.02841   0.01322   0.01842   0.06005        60       640:  50% 27/54 [00:37<00:40,  1.48s/it]Corrupt JPEG data: premature end of data segment\n",
            "     49/49     3.72G   0.02646   0.01329   0.01794    0.0577        58       640: 100% 54/54 [01:13<00:00,  1.36s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:11<00:00,  1.57s/it]\n",
            "                 all         218         218       0.203       0.623       0.237       0.199\n",
            "             downdog         218          45       0.181       0.689         0.2       0.161\n",
            "             goddess         218          36       0.143       0.333       0.144       0.103\n",
            "               plank         218          54       0.202       0.852       0.325       0.278\n",
            "                tree         218          32       0.277       0.438       0.256       0.229\n",
            "            warrior2         218          51       0.214       0.804       0.259       0.223\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "50 epochs completed in 1.160 hours.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/content/yolov7/train.py\", line 513, in train\n",
            "    strip_optimizer(f)  # strip optimizers\n",
            "    ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov7/utils/general.py\", line 802, in strip_optimizer\n",
            "    x = torch.load(f, map_location=torch.device('cpu'))\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1529, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray._reconstruct])` or the `torch.serialization.safe_globals([numpy._core.multiarray._reconstruct])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33my7_tiny_raw_clean3\u001b[0m at: \u001b[34mhttps://wandb.ai/colabclearskysoftware-private/YOLOR/runs/9db2jw2p\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250907_224322-9db2jw2p/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "RUN_NAME = \"y7_tiny_raw_clean3\"  # <- your actual run folder from the log\n",
        "DATA_YAML = \"/content/yolov7/data/yoga_raw_clean.yaml\"\n",
        "\n",
        "RUN_WEIGHTS = Path(f\"runs/train/{RUN_NAME}/weights\")\n",
        "WEIGHTS = RUN_WEIGHTS/\"best.pt\" if (RUN_WEIGHTS/\"best.pt\").exists() else RUN_WEIGHTS/\"last.pt\"\n",
        "assert WEIGHTS.exists(), f\"No weights found under {RUN_WEIGHTS}. Did training finish writing files?\"\n",
        "\n",
        "with open(DATA_YAML, \"r\") as f:\n",
        "    ds = yaml.safe_load(f)\n",
        "\n",
        "TEST_IMAGES_DIR = Path(ds.get(\"test\") or ds[\"val\"])  # fallback to val if no test\n",
        "print(\"Using weights:\", WEIGHTS)\n",
        "print(\"Test images dir:\", TEST_IMAGES_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtZcDLenKZi",
        "outputId": "36538545-29d6-4533-bc36-b6e8131272ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using weights: runs/train/y7_tiny_raw_clean3/weights/best.pt\n",
            "Test images dir: /content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7\n",
        "import sys, runpy, importlib\n",
        "import numpy as np\n",
        "import torch.serialization as ts\n",
        "\n",
        "# 1) YOLO/torch classes you already added (safe to re-add)\n",
        "from models.yolo import Model, Detect\n",
        "from models.common import Conv, Concat, MP, SP\n",
        "from torch.nn.modules import batchnorm, pooling, upsampling, container, activation, conv\n",
        "\n",
        "ts.add_safe_globals([\n",
        "    Model, Detect, Conv, Concat, MP, SP,\n",
        "    batchnorm.BatchNorm2d, pooling.MaxPool2d, upsampling.Upsample,\n",
        "    container.Sequential, container.ModuleList, activation.LeakyReLU, conv.Conv2d\n",
        "])\n",
        "\n",
        "# 2) Add NumPy core types that often appear in checkpoints\n",
        "ts.add_safe_globals([\n",
        "    np.ndarray, np.dtype, np.number, np.integer, np.floating, np.bool_,\n",
        "    np.int8, np.int16, np.int32, np.int64, np.float16, np.float32, np.float64,\n",
        "    # These two are the ones your error mentioned explicitly / commonly needed:\n",
        "    np.dtypes.Float64DType, np.dtypes.Int64DType,\n",
        "])\n",
        "\n",
        "# 3) Old pickling helpers sometimes used in legacy ckpts\n",
        "try:\n",
        "    from numpy._core.multiarray import _reconstruct\n",
        "    ts.add_safe_globals([_reconstruct])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 4) (Optional) introspect and allow-list anything else the ckpt asks for\n",
        "unsafe = ts.get_unsafe_globals_in_checkpoint(str(WEIGHTS))\n",
        "print(\"Still-unsafe before run:\", [u for u in unsafe if u not in {\n",
        "    'numpy.ndarray','numpy.dtype','numpy._core.multiarray._reconstruct',\n",
        "    'numpy._core.multiarray.scalar','numpy.dtypes.Float64DType','numpy.dtypes.Int64DType'\n",
        "}])\n",
        "\n",
        "# 5) Hand off to detect.py exactly like CLI\n",
        "sys.argv = [\n",
        "    \"detect.py\",\n",
        "    \"--weights\", str(WEIGHTS),\n",
        "    \"--img\", \"640\",\n",
        "    \"--conf\", \"0.001\",\n",
        "    \"--source\", str(TEST_IMAGES_DIR),\n",
        "    \"--save-txt\", \"--save-conf\",\n",
        "    \"--name\", f\"{RUN_NAME}_test\"\n",
        "]\n",
        "runpy.run_module(\"detect\", run_name=\"__main__\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEwQ22-znVJL",
        "outputId": "e26a3abd-0aef-4635-abd7-e237b1e7f6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Still-unsafe before run: []\n",
            "Namespace(weights=['runs/train/y7_tiny_raw_clean3/weights/best.pt'], source='/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test', img_size=640, conf_thres=0.001, iou_thres=0.45, device='', view_img=False, save_txt=True, save_conf=True, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='y7_tiny_raw_clean3_test', exist_ok=False, no_trace=False)\n",
            "Fusing layers... \n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 downdogs, 2 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (4.4ms) Inference, (58.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000000.jpg\n",
            "3 downdogs, 1 goddess, 3 planks, 4 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000001.jpg\n",
            "3 downdogs, 4 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000002.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 1 warrior2, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000003.jpg\n",
            "3 downdogs, 1 goddess, 3 planks, 5 trees, 1 warrior2, Done. (9.5ms) Inference, (2.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000004.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 2 trees, 1 warrior2, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000005.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000006.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 3 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000007.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000008.jpg\n",
            "1 downdog, 3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000009.jpg\n",
            "3 downdogs, 3 goddesss, 27 planks, 7 trees, 8 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000010.png\n",
            "2 downdogs, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000011.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000012.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000013.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000014.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000016.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000017.png\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 1 warrior2, Done. (6.3ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000018.jpg\n",
            "3 downdogs, 2 goddesss, 4 planks, 3 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000019.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (4.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000020.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 2 trees, 3 warrior2s, Done. (5.9ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000021.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 4 trees, 2 warrior2s, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000022.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 5 trees, 1 warrior2, Done. (5.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000023.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 5 trees, 3 warrior2s, Done. (8.2ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000024.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (5.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000025.jpg\n",
            "1 downdog, 3 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (8.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000026.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (8.3ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000027.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 1 warrior2, Done. (8.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000029.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 3 trees, 2 warrior2s, Done. (4.9ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000030.jpg\n",
            "1 downdog, 5 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000031.jpg\n",
            "3 downdogs, 2 goddesss, 8 planks, 5 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000032.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (5.0ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000033.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 3 trees, 3 warrior2s, Done. (6.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000035.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000037.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (6.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000038.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 6 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000039.jpg\n",
            "4 downdogs, 4 goddesss, 7 planks, 3 trees, 5 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000040.jpg\n",
            "4 downdogs, 3 goddesss, 6 planks, 5 trees, 3 warrior2s, Done. (5.0ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000041.png\n",
            "4 downdogs, 3 goddesss, 4 planks, 3 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000042.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (5.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000043.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 1 warrior2, Done. (8.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000044.jpg\n",
            "1 downdog, 5 planks, 3 trees, 3 warrior2s, Done. (5.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000045.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000046.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000047.jpg\n",
            "3 downdogs, 3 goddesss, 6 planks, 6 trees, 5 warrior2s, Done. (4.8ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000048.jpg\n",
            "3 downdogs, 2 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (6.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000049.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 4 trees, 2 warrior2s, Done. (5.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000050.jpg\n",
            "3 downdogs, 5 goddesss, 6 planks, 4 trees, 4 warrior2s, Done. (5.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000052.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 6 trees, 2 warrior2s, Done. (6.0ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000053.jpg\n",
            "4 downdogs, 4 goddesss, 7 planks, 3 trees, 5 warrior2s, Done. (6.2ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000054.jpg\n",
            "2 downdogs, 3 goddesss, 7 planks, 3 trees, 8 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000055.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 5 trees, 2 warrior2s, Done. (6.5ms) Inference, (2.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000056.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (6.6ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000057.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (7.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000058.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000059.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000060.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000061.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 4 warrior2s, Done. (5.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000062.jpg\n",
            "4 downdogs, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000064.jpg\n",
            "4 downdogs, 1 goddess, 6 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000067.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 4 trees, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000068.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000074.jpg\n",
            "4 downdogs, 3 goddesss, 6 planks, 5 trees, 3 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000075.png\n",
            "1 downdog, 2 goddesss, 6 planks, 4 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000077.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000080.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000083.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000084.jpg\n",
            "3 downdogs, 5 planks, 3 trees, 2 warrior2s, Done. (5.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000085.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 5 trees, 2 warrior2s, Done. (6.3ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000088.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000089.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 4 warrior2s, Done. (5.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000090.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000092.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 6 trees, 1 warrior2, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000094.jpg\n",
            "1 downdog, 3 goddesss, 4 planks, 5 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000095.jpg\n",
            "4 downdogs, 3 goddesss, 5 planks, 3 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000097.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000098.jpg\n",
            "4 downdogs, 1 goddess, 6 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000099.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 5 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000100.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 4 trees, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000101.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 4 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000102.png\n",
            "1 downdog, 2 goddesss, 6 planks, 4 trees, 2 warrior2s, Done. (4.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000103.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000105.jpg\n",
            "1 downdog, 3 goddesss, 4 planks, 5 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000106.jpg\n",
            "2 downdogs, 1 goddess, 2 planks, 3 trees, 3 warrior2s, Done. (4.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000107.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 3 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000108.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 5 trees, 3 warrior2s, Done. (3.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000109.jpg\n",
            "3 downdogs, 1 goddess, 2 planks, 6 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000111.jpg\n",
            "5 downdogs, 3 goddesss, 10 planks, 9 trees, 8 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000112.jpg\n",
            "4 downdogs, 1 goddess, 9 planks, 4 trees, 4 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000114.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000115.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 5 trees, 1 warrior2, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000118.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000120.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 3 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000121.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 5 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000124.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (4.8ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000125.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 6 trees, 1 warrior2, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000126.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 4 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/downdog__00000127.png\n",
            "2 downdogs, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000000.jpg\n",
            "2 downdogs, 4 planks, 3 trees, 3 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000001.jpg\n",
            "1 downdog, 3 goddesss, 4 planks, 5 trees, 3 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000002.jpeg\n",
            "1 downdog, 2 goddesss, 5 planks, 2 trees, 4 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000003.jpg\n",
            "3 downdogs, 7 planks, 3 trees, 1 warrior2, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000004.jpg\n",
            "3 downdogs, 3 goddesss, 6 planks, 3 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000005.jpg\n",
            "4 downdogs, 2 goddesss, 4 planks, 4 trees, 4 warrior2s, Done. (3.9ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000006.png\n",
            "3 downdogs, 3 goddesss, 22 planks, 5 trees, 4 warrior2s, Done. (3.9ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000007.jpg\n",
            "4 downdogs, 4 goddesss, 8 planks, 5 trees, 8 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000008.jpg\n",
            "5 downdogs, 4 goddesss, 6 planks, 4 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000009.jpg\n",
            "3 downdogs, 2 goddesss, 7 planks, 6 trees, 2 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000010.jpg\n",
            "5 downdogs, 4 goddesss, 9 planks, 4 trees, 8 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000011.jpg\n",
            "4 downdogs, 3 goddesss, 13 planks, 5 trees, 4 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000012.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000013.jpg\n",
            "2 downdogs, 3 goddesss, 46 planks, 5 trees, 3 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000014.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 3 trees, 4 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000015.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000016.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 1 warrior2, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000018.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000019.jpg\n",
            "4 downdogs, 1 goddess, 6 planks, 5 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000020.png\n",
            "1 downdog, 3 goddesss, 6 planks, 5 trees, 6 warrior2s, Done. (6.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000021.png\n",
            "4 downdogs, 2 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000022.jpg\n",
            "7 downdogs, 1 goddess, 13 planks, 3 trees, 9 warrior2s, Done. (4.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000023.jpg\n",
            "6 downdogs, 4 goddesss, 15 planks, 8 trees, 14 warrior2s, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000024.jpg\n",
            "3 downdogs, 3 goddesss, 13 planks, 6 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000025.jpg\n",
            "1 downdog, 4 planks, 2 trees, 1 warrior2, Done. (4.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000027.jpg\n",
            "3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000028.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 1 warrior2, Done. (4.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000029.jpg\n",
            "3 downdogs, 4 goddesss, 9 planks, 7 trees, 2 warrior2s, Done. (5.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000030.jpg\n",
            "2 downdogs, 1 goddess, 7 planks, 5 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000031.jpg\n",
            "2 downdogs, 1 goddess, 6 planks, 1 tree, 4 warrior2s, Done. (4.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000032.jpeg\n",
            "1 downdog, 3 goddesss, 5 planks, 5 trees, 1 warrior2, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000034.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (5.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000036.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 1 tree, 2 warrior2s, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000038.png\n",
            "1 downdog, 2 goddesss, 4 planks, 4 trees, 3 warrior2s, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000039.jpg\n",
            "3 downdogs, 2 goddesss, 10 planks, 5 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000040.jpg\n",
            "4 downdogs, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (5.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000041.jpg\n",
            "4 downdogs, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (6.5ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000042.jpg\n",
            "3 downdogs, 3 goddesss, 6 planks, 3 trees, 2 warrior2s, Done. (4.2ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000045.jpg\n",
            "5 downdogs, 4 goddesss, 7 planks, 4 trees, 4 warrior2s, Done. (5.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000046.jpg\n",
            "4 downdogs, 1 goddess, 7 planks, 4 trees, 4 warrior2s, Done. (4.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000047.png\n",
            "4 downdogs, 2 goddesss, 11 planks, 8 trees, 3 warrior2s, Done. (5.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000049.jpg\n",
            "1 downdog, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (5.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000050.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 4 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000052.jpg\n",
            "3 downdogs, 4 goddesss, 8 planks, 5 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000053.png\n",
            "2 downdogs, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000054.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000055.jpg\n",
            "2 downdogs, 3 goddesss, 46 planks, 5 trees, 3 warrior2s, Done. (4.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000056.jpg\n",
            "3 downdogs, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000057.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 3 trees, 4 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000058.jpg\n",
            "5 downdogs, 4 goddesss, 6 planks, 4 trees, 3 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000059.jpg\n",
            "2 downdogs, 3 goddesss, 2 planks, 5 trees, 2 warrior2s, Done. (4.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000060.jpg\n",
            "2 downdogs, 6 planks, 4 trees, 4 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000062.jpg\n",
            "7 downdogs, 1 goddess, 13 planks, 3 trees, 9 warrior2s, Done. (4.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000063.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 5 trees, Done. (4.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000067.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 6 trees, 4 warrior2s, Done. (5.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000068.jpg\n",
            "5 downdogs, 3 goddesss, 17 planks, 6 trees, 6 warrior2s, Done. (5.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000069.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000071.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000072.jpg\n",
            "2 downdogs, 1 goddess, 6 planks, 3 trees, 2 warrior2s, Done. (4.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000073.jpg\n",
            "5 downdogs, 4 goddesss, 9 planks, 4 trees, 7 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000074.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 1 warrior2, Done. (3.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000076.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 3 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000077.jpg\n",
            "3 downdogs, 2 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000078.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 1 warrior2, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000079.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 1 tree, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000080.jpg\n",
            "6 downdogs, 9 planks, 4 trees, 6 warrior2s, Done. (4.5ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000081.jpg\n",
            "4 downdogs, 3 goddesss, 23 planks, 3 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000082.jpg\n",
            "3 downdogs, 2 goddesss, 7 planks, 6 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000083.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 5 trees, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000084.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 3 trees, 3 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000085.jpg\n",
            "1 downdog, 3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000086.jpg\n",
            "2 downdogs, 6 planks, 4 trees, 4 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000087.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (3.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000088.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 2 warrior2s, Done. (3.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000089.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 5 trees, 1 warrior2, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000090.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (7.4ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000091.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 4 trees, 5 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000092.png\n",
            "2 downdogs, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000093.jpg\n",
            "1 downdog, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/goddess__00000095.jpeg\n",
            "2 downdogs, 1 goddess, 2 planks, 4 trees, 1 warrior2, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000000.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 1 tree, 2 warrior2s, Done. (4.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000001.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000002.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 2 trees, 1 warrior2, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000004.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 3 trees, 1 warrior2, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000005.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 3 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000006.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000007.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 6 trees, 1 warrior2, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000008.jpg\n",
            "3 downdogs, 5 planks, 2 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000010.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 3 trees, 2 warrior2s, Done. (3.8ms) Inference, (2.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000011.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 4 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000012.jpg\n",
            "3 downdogs, 4 planks, 3 trees, 2 warrior2s, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000013.jpg\n",
            "1 downdog, 4 planks, 2 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000014.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 5 trees, 2 warrior2s, Done. (4.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000015.jpg\n",
            "2 downdogs, 4 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000016.jpg\n",
            "3 downdogs, 1 goddess, 11 planks, 4 trees, 8 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000017.jpg\n",
            "2 downdogs, 1 goddess, 2 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000018.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 3 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000019.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 3 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000020.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000021.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 6 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000022.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 5 trees, 1 warrior2, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000024.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 2 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000025.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000026.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 2 trees, 1 warrior2, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000027.jpg\n",
            "4 downdogs, 1 goddess, 4 planks, 4 trees, 4 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000028.jpg\n",
            "1 downdog, 2 goddesss, 6 planks, 3 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000029.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000030.jpg\n",
            "3 downdogs, 2 goddesss, 6 planks, 5 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000031.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000032.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (6.5ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000033.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 2 trees, 2 warrior2s, Done. (5.5ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000034.jpg\n",
            "2 downdogs, 1 goddess, 2 planks, 3 trees, 1 warrior2, Done. (5.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000036.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 5 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000037.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 3 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000038.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000039.jpg\n",
            "4 downdogs, 3 goddesss, 8 planks, 5 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000040.jpg\n",
            "4 downdogs, 3 goddesss, 7 planks, 4 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000042.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000043.jpg\n",
            "4 downdogs, 1 goddess, 4 planks, 4 trees, 4 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000044.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000045.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 2 trees, 2 warrior2s, Done. (6.5ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000047.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (6.2ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000049.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 5 trees, 1 warrior2, Done. (5.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000050.png\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 2 warrior2s, Done. (5.0ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000052.jpg\n",
            "3 downdogs, 2 goddesss, 6 planks, 4 trees, 6 warrior2s, Done. (5.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000053.jpg\n",
            "5 downdogs, 2 goddesss, 5 planks, 3 trees, 4 warrior2s, Done. (5.0ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000054.png\n",
            "1 downdog, 3 goddesss, 1 plank, 5 trees, 1 warrior2, Done. (5.4ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000055.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 2 trees, 2 warrior2s, Done. (4.9ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000056.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (5.6ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000058.png\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000059.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 5 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000060.jpg\n",
            "4 downdogs, 3 goddesss, 8 planks, 5 trees, 2 warrior2s, Done. (7.5ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000061.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 3 trees, 1 warrior2, Done. (8.3ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000062.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (5.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000063.jpg\n",
            "4 downdogs, 34 goddesss, 156 planks, 9 trees, 2 warrior2s, Done. (5.8ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000064.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 3 trees, 1 warrior2, Done. (5.1ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000065.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (5.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000066.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000068.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 2 warrior2s, Done. (5.6ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000069.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 4 trees, 4 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000071.jpg\n",
            "1 downdog, 3 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (5.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000072.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (5.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000073.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 5 trees, 3 warrior2s, Done. (6.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000074.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (5.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000075.png\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 5 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000076.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 2 trees, 2 warrior2s, Done. (11.3ms) Inference, (2.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000077.jpg\n",
            "1 downdog, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (5.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000078.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (5.7ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000079.png\n",
            "1 downdog, 3 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000081.jpg\n",
            "1 downdog, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (5.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000082.jpg\n",
            "3 downdogs, 3 goddesss, 6 planks, 4 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000083.jpeg\n",
            "2 downdogs, 1 goddess, 2 planks, 3 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000084.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000085.jpg\n",
            "1 downdog, 5 planks, 4 trees, 2 warrior2s, Done. (8.6ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000087.jpg\n",
            "4 downdogs, 2 goddesss, 6 planks, 5 trees, 5 warrior2s, Done. (7.2ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000088.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 3 trees, 3 warrior2s, Done. (6.3ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000089.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (6.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000090.png\n",
            "1 downdog, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (5.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000091.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (7.2ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000092.png\n",
            "2 downdogs, 5 planks, 4 trees, 3 warrior2s, Done. (6.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000093.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (6.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000094.jpg\n",
            "2 downdogs, 1 goddess, 61 planks, 5 trees, 4 warrior2s, Done. (5.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000095.jpg\n",
            "2 downdogs, 3 goddesss, 13 planks, 5 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000096.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000097.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 7 trees, 3 warrior2s, Done. (5.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000098.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 2 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000099.jpg\n",
            "1 downdog, 3 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000100.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 6 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000101.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 4 trees, 5 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000102.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 3 trees, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000103.jpg\n",
            "1 downdog, 3 goddesss, 6 planks, 5 trees, 1 warrior2, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000104.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000105.png\n",
            "2 downdogs, 3 goddesss, 3 planks, 3 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000106.jpg\n",
            "4 downdogs, 1 goddess, 6 planks, 5 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000107.jpg\n",
            "3 downdogs, 1 goddess, 6 planks, 6 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000108.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000109.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 3 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000110.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 2 trees, 1 warrior2, Done. (6.3ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000111.jpg\n",
            "2 downdogs, 2 goddesss, 7 planks, 6 trees, 4 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000112.jpg\n",
            "3 downdogs, 4 goddesss, 31 planks, 4 trees, 4 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000113.jpg\n",
            "3 downdogs, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000114.png\n",
            "1 downdog, 2 goddesss, 2 planks, 4 trees, 1 warrior2, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000115.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000116.png\n",
            "4 downdogs, 1 goddess, 11 planks, 4 trees, 4 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000117.jpg\n",
            "3 downdogs, 5 planks, 3 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000118.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 3 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000119.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000120.png\n",
            "2 downdogs, 1 goddess, 61 planks, 5 trees, 4 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000121.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 5 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000122.jpg\n",
            "2 downdogs, 2 goddesss, 6 planks, 7 trees, 3 warrior2s, Done. (4.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000123.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 6 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000124.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000125.jpg\n",
            "1 downdog, 6 planks, 4 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000126.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 2 trees, 3 warrior2s, Done. (3.9ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/plank__00000127.jpg\n",
            "2 downdogs, 4 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000000.jpg\n",
            "4 downdogs, 3 goddesss, 41 planks, 4 trees, 4 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000001.jpg\n",
            "3 downdogs, 3 goddesss, 48 planks, 5 trees, 5 warrior2s, Done. (16.2ms) Inference, (11.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000002.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000003.jpg\n",
            "4 downdogs, 3 goddesss, 48 planks, 3 trees, 7 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000004.jpg\n",
            "3 downdogs, 2 goddesss, 33 planks, 3 trees, 2 warrior2s, Done. (5.3ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000005.jpg\n",
            "3 downdogs, 2 goddesss, 36 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000006.jpg\n",
            "4 downdogs, 3 goddesss, 40 planks, 4 trees, 4 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000007.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 1 warrior2, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000008.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000009.jpg\n",
            "3 downdogs, 4 goddesss, 40 planks, 3 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000010.jpg\n",
            "2 downdogs, 2 goddesss, 2 planks, 4 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000011.jpg\n",
            "3 downdogs, 1 goddess, 4 planks, 2 trees, 2 warrior2s, Done. (4.7ms) Inference, (2.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000012.jpg\n",
            "3 downdogs, 4 goddesss, 3 planks, 4 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000013.jpg\n",
            "4 downdogs, 3 goddesss, 46 planks, 3 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000014.jpg\n",
            "4 downdogs, 4 goddesss, 40 planks, 3 trees, 4 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000015.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000016.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 4 trees, 1 warrior2, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000017.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 4 trees, 1 warrior2, Done. (4.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000018.jpg\n",
            "4 goddesss, 2 planks, 5 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000019.png\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000020.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (5.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000021.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000022.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 2 trees, 1 warrior2, Done. (4.7ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000023.jpg\n",
            "3 downdogs, 4 goddesss, 3 planks, 4 trees, 3 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000024.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 1 warrior2, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000025.jpg\n",
            "3 downdogs, 4 goddesss, 12 planks, 5 trees, 2 warrior2s, Done. (5.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000026.jpg\n",
            "4 downdogs, 4 goddesss, 5 planks, 5 trees, 5 warrior2s, Done. (5.6ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000027.jpg\n",
            "4 downdogs, 2 goddesss, 5 planks, 4 trees, 4 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000028.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 1 warrior2, Done. (4.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000029.jpg\n",
            "2 downdogs, 10 planks, 2 trees, 8 warrior2s, Done. (4.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000030.jpg\n",
            "4 downdogs, 3 goddesss, 36 planks, 3 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000031.jpg\n",
            "2 downdogs, 5 goddesss, 3 planks, 3 trees, 3 warrior2s, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000032.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (4.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000033.jpg\n",
            "4 downdogs, 4 goddesss, 24 planks, 4 trees, 7 warrior2s, Done. (4.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000034.jpg\n",
            "3 downdogs, 3 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000035.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 3 trees, 3 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000036.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000037.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 4 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000038.jpg\n",
            "4 downdogs, 1 goddess, 7 planks, 4 trees, 3 warrior2s, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000039.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 4 trees, 3 warrior2s, Done. (5.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000040.jpg\n",
            "1 downdog, 4 goddesss, 1 plank, 5 trees, 1 warrior2, Done. (4.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000041.jpg\n",
            "4 downdogs, 3 goddesss, 3 planks, 4 trees, 5 warrior2s, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000042.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 2 warrior2s, Done. (4.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000043.jpg\n",
            "3 downdogs, 3 goddesss, 3 planks, 3 trees, 4 warrior2s, Done. (5.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000044.jpg\n",
            "2 downdogs, 4 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000045.jpg\n",
            "3 downdogs, 3 goddesss, 4 planks, 4 trees, 1 warrior2, Done. (4.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000046.jpg\n",
            "4 goddesss, 2 planks, 5 trees, 2 warrior2s, Done. (4.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000047.png\n",
            "1 downdog, 3 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000048.jpg\n",
            "2 downdogs, 3 goddesss, 5 planks, 3 trees, 5 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000049.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 4 trees, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000050.jpg\n",
            "1 downdog, 3 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000051.png\n",
            "2 downdogs, 3 goddesss, 3 planks, 5 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000052.jpg\n",
            "3 downdogs, 2 goddesss, 93 planks, 5 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000053.jpg\n",
            "3 downdogs, 2 goddesss, 138 planks, 5 trees, 1 warrior2, Done. (4.5ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000054.jpg\n",
            "4 downdogs, 1 goddess, 4 planks, 4 trees, 5 warrior2s, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000055.jpg\n",
            "1 downdog, 4 goddesss, 3 planks, 5 trees, 3 warrior2s, Done. (5.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000056.jpg\n",
            "4 downdogs, 4 goddesss, 5 planks, 5 trees, 5 warrior2s, Done. (7.8ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000057.jpg\n",
            "4 downdogs, 3 goddesss, 36 planks, 3 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000058.jpg\n",
            "3 downdogs, 1 goddess, 39 planks, 5 trees, 2 warrior2s, Done. (5.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000059.jpg\n",
            "3 downdogs, 4 goddesss, 40 planks, 3 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000060.jpg\n",
            "3 downdogs, 3 goddesss, 4 planks, 5 trees, 2 warrior2s, Done. (5.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000061.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 1 warrior2, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000062.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 3 trees, 1 warrior2, Done. (5.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000063.jpg\n",
            "3 downdogs, 3 goddesss, 80 planks, 4 trees, 3 warrior2s, Done. (6.2ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000064.jpg\n",
            "4 downdogs, 4 goddesss, 39 planks, 4 trees, 4 warrior2s, Done. (4.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000065.jpg\n",
            "4 downdogs, 3 goddesss, 48 planks, 3 trees, 7 warrior2s, Done. (5.2ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000067.jpg\n",
            "10 downdogs, 9 planks, 4 trees, 10 warrior2s, Done. (5.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000068.png\n",
            "1 downdog, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (5.0ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/tree__00000069.jpg\n",
            "4 downdogs, 2 goddesss, 6 planks, 1 tree, 5 warrior2s, Done. (5.4ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000000.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (12.3ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000001.jpg\n",
            "2 downdogs, 3 goddesss, 6 planks, 2 trees, 4 warrior2s, Done. (5.4ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000002.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 1 warrior2, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000003.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000004.jpg\n",
            "1 downdog, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (5.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000005.jpg\n",
            "3 downdogs, 3 goddesss, 5 planks, 5 trees, 2 warrior2s, Done. (5.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000006.png\n",
            "2 downdogs, 1 goddess, 4 planks, 2 trees, 1 warrior2, Done. (4.9ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000007.png\n",
            "3 downdogs, 3 goddesss, 8 planks, 4 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000008.jpg\n",
            "3 downdogs, 2 goddesss, 5 planks, 6 trees, 4 warrior2s, Done. (5.0ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000009.jpg\n",
            "3 downdogs, 2 goddesss, 7 planks, 6 trees, 2 warrior2s, Done. (5.5ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000010.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 1 warrior2, Done. (8.9ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000011.jpg\n",
            "5 downdogs, 2 goddesss, 6 planks, 5 trees, 2 warrior2s, Done. (5.4ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000012.jpg\n",
            "4 downdogs, 1 goddess, 10 planks, 3 trees, 5 warrior2s, Done. (5.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000013.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 3 trees, 3 warrior2s, Done. (7.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000014.jpg\n",
            "4 downdogs, 3 goddesss, 11 planks, 4 trees, 4 warrior2s, Done. (6.5ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000015.jpg\n",
            "2 goddesss, 4 planks, 4 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000016.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000017.jpg\n",
            "2 downdogs, 5 planks, 3 trees, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000018.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 1 warrior2, Done. (5.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000019.jpg\n",
            "4 downdogs, 2 goddesss, 7 planks, 5 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000020.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 7 trees, 3 warrior2s, Done. (5.5ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000021.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (5.7ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000022.jpg\n",
            "3 downdogs, 3 goddesss, 34 planks, 4 trees, 4 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000023.jpg\n",
            "4 downdogs, 5 goddesss, 5 planks, 3 trees, 1 warrior2, Done. (6.3ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000024.jpg\n",
            "3 downdogs, 3 goddesss, 8 planks, 4 trees, 2 warrior2s, Done. (6.3ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000025.png\n",
            "1 downdog, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (7.5ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000026.jpg\n",
            "4 downdogs, 1 goddess, 19 planks, 4 trees, 3 warrior2s, Done. (5.9ms) Inference, (4.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000027.jpg\n",
            "4 downdogs, 3 goddesss, 11 planks, 4 trees, 4 warrior2s, Done. (4.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000029.jpg\n",
            "4 downdogs, 2 goddesss, 7 planks, 5 trees, 3 warrior2s, Done. (6.4ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000030.jpg\n",
            "1 downdog, 1 goddess, 1 plank, 2 trees, 2 warrior2s, Done. (6.9ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000031.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 3 warrior2s, Done. (6.6ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000032.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (6.7ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000033.jpg\n",
            "4 downdogs, 5 goddesss, 5 planks, 3 trees, 1 warrior2, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000034.jpg\n",
            "1 downdog, 2 goddesss, 3 planks, 3 trees, 1 warrior2, Done. (5.5ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000035.jpg\n",
            "3 downdogs, 2 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000036.jpg\n",
            "1 downdog, 2 goddesss, 5 planks, 4 trees, 1 warrior2, Done. (5.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000037.jpg\n",
            "1 downdog, 2 goddesss, 4 planks, 5 trees, 1 warrior2, Done. (4.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000038.jpg\n",
            "3 downdogs, 3 goddesss, 8 planks, 4 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000039.png\n",
            "4 downdogs, 3 goddesss, 4 planks, 7 trees, 3 warrior2s, Done. (5.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000040.jpg\n",
            "3 downdogs, 3 goddesss, 34 planks, 4 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000041.jpg\n",
            "2 downdogs, 2 goddesss, 4 planks, 3 trees, 1 warrior2, Done. (4.2ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000042.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 6 trees, 1 warrior2, Done. (6.2ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000043.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 1 warrior2, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000044.jpg\n",
            "1 downdog, 3 goddesss, 3 planks, 6 trees, 2 warrior2s, Done. (5.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000045.png\n",
            "3 downdogs, 1 goddess, 5 planks, 7 trees, 1 warrior2, Done. (11.5ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000046.jpg\n",
            "2 downdogs, 3 goddesss, 3 planks, 4 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000047.jpg\n",
            "3 downdogs, 3 goddesss, 3 planks, 5 trees, 3 warrior2s, Done. (5.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000048.jpg\n",
            "5 downdogs, 2 goddesss, 7 planks, 5 trees, 3 warrior2s, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000049.jpg\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 2 warrior2s, Done. (4.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000050.jpg\n",
            "4 downdogs, 8 goddesss, 54 planks, 5 trees, 4 warrior2s, Done. (5.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000051.jpg\n",
            "4 downdogs, 3 goddesss, 11 planks, 4 trees, 4 warrior2s, Done. (4.3ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000052.jpg\n",
            "2 downdogs, 2 goddesss, 7 planks, 2 trees, 7 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000053.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (5.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000054.jpg\n",
            "4 downdogs, 2 goddesss, 10 planks, 5 trees, 4 warrior2s, Done. (5.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000055.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 4 trees, 2 warrior2s, Done. (4.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000057.png\n",
            "1 downdog, 3 goddesss, 7 planks, 5 trees, Done. (4.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000058.jpg\n",
            "3 downdogs, 33 goddesss, 74 planks, 6 trees, 3 warrior2s, Done. (5.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000059.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000060.jpg\n",
            "2 downdogs, 3 goddesss, 5 planks, 5 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000061.jpg\n",
            "3 downdogs, 4 goddesss, 6 planks, 7 trees, 3 warrior2s, Done. (5.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000062.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 2 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000063.jpg\n",
            "3 downdogs, 5 goddesss, 55 planks, 4 trees, 6 warrior2s, Done. (7.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000064.jpg\n",
            "4 downdogs, 5 goddesss, 34 planks, 8 trees, 12 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000065.jpg\n",
            "3 downdogs, 32 goddesss, 148 planks, 8 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000066.jpg\n",
            "1 downdog, 1 goddess, 30 planks, 3 trees, 3 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000067.jpg\n",
            "5 downdogs, 1 goddess, 13 planks, 5 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000068.jpg\n",
            "5 downdogs, 5 goddesss, 29 planks, 8 trees, 12 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000070.jpg\n",
            "2 downdogs, 1 goddess, 7 planks, 5 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000071.png\n",
            "1 downdog, 2 goddesss, 4 planks, 5 trees, 1 warrior2, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000073.jpg\n",
            "3 downdogs, 1 goddess, 5 planks, 7 trees, 1 warrior2, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000074.jpg\n",
            "4 downdogs, 8 goddesss, 54 planks, 5 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000075.jpg\n",
            "1 downdog, 1 goddess, 5 planks, 3 trees, 1 warrior2, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000076.jpg\n",
            "4 downdogs, 2 goddesss, 5 planks, 5 trees, 3 warrior2s, Done. (4.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000077.jpg\n",
            "3 downdogs, 3 goddesss, 3 planks, 5 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000078.jpg\n",
            "4 downdogs, 2 goddesss, 10 planks, 5 trees, 4 warrior2s, Done. (4.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000080.jpg\n",
            "4 downdogs, 5 goddesss, 34 planks, 8 trees, 12 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000081.jpg\n",
            "1 downdog, 3 goddesss, 7 planks, 5 trees, Done. (4.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000082.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 4 trees, 2 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000083.png\n",
            "5 downdogs, 2 goddesss, 7 planks, 5 trees, 3 warrior2s, Done. (3.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000084.jpg\n",
            "2 downdogs, 1 goddess, 6 planks, 4 trees, 3 warrior2s, Done. (4.6ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000085.jpg\n",
            "6 downdogs, 2 goddesss, 7 planks, 4 trees, 3 warrior2s, Done. (4.8ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000086.jpg\n",
            "4 downdogs, 3 goddesss, 11 planks, 4 trees, 4 warrior2s, Done. (3.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000087.jpg\n",
            "3 downdogs, 5 goddesss, 61 planks, 5 trees, 6 warrior2s, Done. (3.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000088.jpg\n",
            "1 downdog, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000089.jpg\n",
            "3 downdogs, 5 goddesss, 2 planks, 5 trees, 1 warrior2, Done. (4.0ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000090.jpg\n",
            "2 downdogs, 2 goddesss, 5 planks, 4 trees, 2 warrior2s, Done. (3.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000092.jpg\n",
            "3 downdogs, 32 goddesss, 148 planks, 8 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000093.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000094.jpg\n",
            "2 downdogs, 2 goddesss, 3 planks, 4 trees, 4 warrior2s, Done. (5.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000095.jpg\n",
            "2 downdogs, 1 goddess, 5 planks, 2 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000096.jpg\n",
            "3 downdogs, 33 goddesss, 74 planks, 6 trees, 3 warrior2s, Done. (5.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000097.jpg\n",
            "3 downdogs, 2 goddesss, 9 planks, 6 trees, 4 warrior2s, Done. (5.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000099.jpg\n",
            "3 downdogs, 17 goddesss, 63 planks, 4 trees, 3 warrior2s, Done. (5.5ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000100.jpg\n",
            "3 downdogs, 3 goddesss, 6 planks, 3 trees, 4 warrior2s, Done. (4.6ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000101.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 1 tree, 1 warrior2, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000102.jpg\n",
            "2 downdogs, 1 goddess, 3 planks, 3 trees, 3 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000104.jpg\n",
            "2 downdogs, 3 goddesss, 5 planks, 5 trees, 3 warrior2s, Done. (5.7ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000105.jpg\n",
            "2 downdogs, 1 goddess, 7 planks, 5 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000106.png\n",
            "1 downdog, 2 goddesss, 2 planks, 3 trees, 2 warrior2s, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000107.jpg\n",
            "4 downdogs, 1 goddess, 8 planks, 8 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000108.jpg\n",
            "5 downdogs, 1 goddess, 13 planks, 5 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000110.jpg\n",
            "3 downdogs, 3 goddesss, 12 planks, 8 trees, 10 warrior2s, Done. (4.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000111.jpg\n",
            "1 downdog, 5 planks, 2 trees, 3 warrior2s, Done. (4.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000112.jpg\n",
            "1 downdog, 1 goddess, 1 plank, 2 trees, 2 warrior2s, Done. (4.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000113.jpg\n",
            "2 downdogs, 3 goddesss, 4 planks, 2 trees, 2 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000114.jpg\n",
            "4 downdogs, 3 goddesss, 4 planks, 5 trees, 5 warrior2s, Done. (5.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000115.png\n",
            "4 downdogs, 1 goddess, 8 planks, 8 trees, 2 warrior2s, Done. (4.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000116.jpg\n",
            "2 downdogs, 1 goddess, 4 planks, 1 tree, 1 warrior2, Done. (4.7ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/y7_tiny_raw_clean3_test2/warrior2__00000117.jpg\n",
            "Done. (36.761s)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__name__': '__main__',\n",
              " '__file__': '/content/yolov7/detect.py',\n",
              " '__cached__': '/content/yolov7/__pycache__/detect.cpython-312.pyc',\n",
              " '__doc__': None,\n",
              " '__loader__': <_frozen_importlib_external.SourceFileLoader at 0x7d048f643ce0>,\n",
              " '__package__': '',\n",
              " '__spec__': ModuleSpec(name='detect', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7d048f643ce0>, origin='/content/yolov7/detect.py'),\n",
              " '__builtins__': {'__name__': 'builtins',\n",
              "  '__doc__': \"Built-in functions, types, exceptions, and other objects.\\n\\nThis module provides direct access to all 'built-in'\\nidentifiers of Python; for example, builtins.len is\\nthe full name for the built-in function len().\\n\\nThis module is not normally accessed explicitly by most\\napplications, but can be useful in modules that provide\\nobjects with the same name as a built-in value, but in\\nwhich the built-in of that name is also needed.\",\n",
              "  '__package__': '',\n",
              "  '__loader__': _frozen_importlib.BuiltinImporter,\n",
              "  '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
              "  '__build_class__': <function __build_class__>,\n",
              "  '__import__': <function __import__(name, globals=None, locals=None, fromlist=(), level=0)>,\n",
              "  'abs': <function abs(x, /)>,\n",
              "  'all': <function all(iterable, /)>,\n",
              "  'any': <function any(iterable, /)>,\n",
              "  'ascii': <function ascii(obj, /)>,\n",
              "  'bin': <function bin(number, /)>,\n",
              "  'breakpoint': <function breakpoint>,\n",
              "  'callable': <function callable(obj, /)>,\n",
              "  'chr': <function chr(i, /)>,\n",
              "  'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
              "  'delattr': <function delattr(obj, name, /)>,\n",
              "  'dir': <function dir>,\n",
              "  'divmod': <function divmod(x, y, /)>,\n",
              "  'eval': <function eval(source, globals=None, locals=None, /)>,\n",
              "  'exec': <function exec(source, globals=None, locals=None, /, *, closure=None)>,\n",
              "  'format': <function format(value, format_spec='', /)>,\n",
              "  'getattr': <function getattr>,\n",
              "  'globals': <function globals()>,\n",
              "  'hasattr': <function hasattr(obj, name, /)>,\n",
              "  'hash': <function hash(obj, /)>,\n",
              "  'hex': <function hex(number, /)>,\n",
              "  'id': <function id(obj, /)>,\n",
              "  'input': <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7d05e38374d0>>,\n",
              "  'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
              "  'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
              "  'iter': <function iter>,\n",
              "  'aiter': <function aiter(async_iterable, /)>,\n",
              "  'len': <function len(obj, /)>,\n",
              "  'locals': <function locals()>,\n",
              "  'max': <function max>,\n",
              "  'min': <function min>,\n",
              "  'next': <function next>,\n",
              "  'anext': <function anext>,\n",
              "  'oct': <function oct(number, /)>,\n",
              "  'ord': <function ord(c, /)>,\n",
              "  'pow': <function pow(base, exp, mod=None)>,\n",
              "  'print': <function print(*args, sep=' ', end='\\n', file=None, flush=False)>,\n",
              "  'repr': <function repr(obj, /)>,\n",
              "  'round': <function round(number, ndigits=None)>,\n",
              "  'setattr': <function setattr(obj, name, value, /)>,\n",
              "  'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
              "  'sum': <function sum(iterable, /, start=0)>,\n",
              "  'vars': <function vars>,\n",
              "  'None': None,\n",
              "  'Ellipsis': Ellipsis,\n",
              "  'NotImplemented': NotImplemented,\n",
              "  'False': False,\n",
              "  'True': True,\n",
              "  'bool': bool,\n",
              "  'memoryview': memoryview,\n",
              "  'bytearray': bytearray,\n",
              "  'bytes': bytes,\n",
              "  'classmethod': classmethod,\n",
              "  'complex': complex,\n",
              "  'dict': dict,\n",
              "  'enumerate': enumerate,\n",
              "  'filter': filter,\n",
              "  'float': float,\n",
              "  'frozenset': frozenset,\n",
              "  'property': property,\n",
              "  'int': int,\n",
              "  'list': list,\n",
              "  'map': map,\n",
              "  'object': object,\n",
              "  'range': range,\n",
              "  'reversed': reversed,\n",
              "  'set': set,\n",
              "  'slice': slice,\n",
              "  'staticmethod': staticmethod,\n",
              "  'str': str,\n",
              "  'super': super,\n",
              "  'tuple': tuple,\n",
              "  'type': type,\n",
              "  'zip': zip,\n",
              "  '__debug__': True,\n",
              "  'BaseException': BaseException,\n",
              "  'BaseExceptionGroup': BaseExceptionGroup,\n",
              "  'Exception': Exception,\n",
              "  'GeneratorExit': GeneratorExit,\n",
              "  'KeyboardInterrupt': KeyboardInterrupt,\n",
              "  'SystemExit': SystemExit,\n",
              "  'ArithmeticError': ArithmeticError,\n",
              "  'AssertionError': AssertionError,\n",
              "  'AttributeError': AttributeError,\n",
              "  'BufferError': BufferError,\n",
              "  'EOFError': EOFError,\n",
              "  'ImportError': ImportError,\n",
              "  'LookupError': LookupError,\n",
              "  'MemoryError': MemoryError,\n",
              "  'NameError': NameError,\n",
              "  'OSError': OSError,\n",
              "  'ReferenceError': ReferenceError,\n",
              "  'RuntimeError': RuntimeError,\n",
              "  'StopAsyncIteration': StopAsyncIteration,\n",
              "  'StopIteration': StopIteration,\n",
              "  'SyntaxError': SyntaxError,\n",
              "  'SystemError': SystemError,\n",
              "  'TypeError': TypeError,\n",
              "  'ValueError': ValueError,\n",
              "  'Warning': Warning,\n",
              "  'FloatingPointError': FloatingPointError,\n",
              "  'OverflowError': OverflowError,\n",
              "  'ZeroDivisionError': ZeroDivisionError,\n",
              "  'BytesWarning': BytesWarning,\n",
              "  'DeprecationWarning': DeprecationWarning,\n",
              "  'EncodingWarning': EncodingWarning,\n",
              "  'FutureWarning': FutureWarning,\n",
              "  'ImportWarning': ImportWarning,\n",
              "  'PendingDeprecationWarning': PendingDeprecationWarning,\n",
              "  'ResourceWarning': ResourceWarning,\n",
              "  'RuntimeWarning': RuntimeWarning,\n",
              "  'SyntaxWarning': SyntaxWarning,\n",
              "  'UnicodeWarning': UnicodeWarning,\n",
              "  'UserWarning': UserWarning,\n",
              "  'BlockingIOError': BlockingIOError,\n",
              "  'ChildProcessError': ChildProcessError,\n",
              "  'ConnectionError': ConnectionError,\n",
              "  'FileExistsError': FileExistsError,\n",
              "  'FileNotFoundError': FileNotFoundError,\n",
              "  'InterruptedError': InterruptedError,\n",
              "  'IsADirectoryError': IsADirectoryError,\n",
              "  'NotADirectoryError': NotADirectoryError,\n",
              "  'PermissionError': PermissionError,\n",
              "  'ProcessLookupError': ProcessLookupError,\n",
              "  'TimeoutError': TimeoutError,\n",
              "  'IndentationError': IndentationError,\n",
              "  'IndexError': IndexError,\n",
              "  'KeyError': KeyError,\n",
              "  'ModuleNotFoundError': ModuleNotFoundError,\n",
              "  'NotImplementedError': NotImplementedError,\n",
              "  'RecursionError': RecursionError,\n",
              "  'UnboundLocalError': UnboundLocalError,\n",
              "  'UnicodeError': UnicodeError,\n",
              "  'BrokenPipeError': BrokenPipeError,\n",
              "  'ConnectionAbortedError': ConnectionAbortedError,\n",
              "  'ConnectionRefusedError': ConnectionRefusedError,\n",
              "  'ConnectionResetError': ConnectionResetError,\n",
              "  'TabError': TabError,\n",
              "  'UnicodeDecodeError': UnicodeDecodeError,\n",
              "  'UnicodeEncodeError': UnicodeEncodeError,\n",
              "  'UnicodeTranslateError': UnicodeTranslateError,\n",
              "  'ExceptionGroup': ExceptionGroup,\n",
              "  'EnvironmentError': OSError,\n",
              "  'IOError': OSError,\n",
              "  'open': <function _io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
              "  'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 2000 BeOpen.com.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
              "  All Rights Reserved.\n",
              "  \n",
              "  Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
              "  All Rights Reserved.,\n",
              "  'credits':     Thanks to CWI, CNRI, BeOpen, Zope Corporation, the Python Software\n",
              "      Foundation, and a cast of thousands for supporting Python\n",
              "      development.  See www.python.org for more information.,\n",
              "  'license': Type license() to see the full license text,\n",
              "  'help': Type help() for interactive help, or help(object) for help about object.,\n",
              "  'execfile': <function _pydev_bundle._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
              "  'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
              "  '__IPYTHON__': True,\n",
              "  'display': <function IPython.core.display.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, **kwargs)>,\n",
              "  'get_ipython': <bound method InteractiveShell.get_ipython of <google.colab._shell.Shell object at 0x7d05e3837770>>},\n",
              " 'argparse': <module 'argparse' from '/usr/lib/python3.12/argparse.py'>,\n",
              " 'time': <module 'time' (built-in)>,\n",
              " 'Path': pathlib.Path,\n",
              " 'cv2': <module 'cv2' (<google.colab._import_hooks._hook_injector.HookInjectorLoader object at 0x7d04bcec7710>)>,\n",
              " 'torch': <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'>,\n",
              " 'cudnn': <module 'torch.backends.cudnn' from '/usr/local/lib/python3.12/dist-packages/torch/backends/cudnn/__init__.py'>,\n",
              " 'random': <module 'numpy.random' from '/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py'>,\n",
              " 'attempt_load': <function models.experimental.attempt_load(weights, map_location=None)>,\n",
              " 'LoadStreams': utils.datasets.LoadStreams,\n",
              " 'LoadImages': utils.datasets.LoadImages,\n",
              " 'check_img_size': <function utils.general.check_img_size(img_size, s=32)>,\n",
              " 'check_requirements': <function utils.general.check_requirements(requirements='requirements.txt', exclude=())>,\n",
              " 'check_imshow': <function utils.general.check_imshow()>,\n",
              " 'non_max_suppression': <function utils.general.non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False, labels=())>,\n",
              " 'apply_classifier': <function utils.general.apply_classifier(x, model, img, im0)>,\n",
              " 'scale_coords': <function utils.general.scale_coords(img1_shape, coords, img0_shape, ratio_pad=None)>,\n",
              " 'xyxy2xywh': <function utils.general.xyxy2xywh(x)>,\n",
              " 'strip_optimizer': <function utils.general.strip_optimizer(f='best.pt', s='')>,\n",
              " 'set_logging': <function utils.general.set_logging(rank=-1)>,\n",
              " 'increment_path': <function utils.general.increment_path(path, exist_ok=True, sep='')>,\n",
              " 'plot_one_box': <function utils.plots.plot_one_box(x, img, color=None, label=None, line_thickness=3)>,\n",
              " 'select_device': <function utils.torch_utils.select_device(device='', batch_size=None)>,\n",
              " 'load_classifier': <function utils.torch_utils.load_classifier(name='resnet101', n=2)>,\n",
              " 'time_synchronized': <function utils.torch_utils.time_synchronized()>,\n",
              " 'TracedModel': utils.torch_utils.TracedModel,\n",
              " 'detect': <function __main__.detect(save_img=False)>,\n",
              " 'parser': ArgumentParser(prog='detect.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True),\n",
              " 'opt': Namespace(weights=['runs/train/y7_tiny_raw_clean3/weights/best.pt'], source='/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test', img_size=640, conf_thres=0.001, iou_thres=0.45, device='', view_img=False, save_txt=True, save_conf=True, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='y7_tiny_raw_clean3_test', exist_ok=False, no_trace=False)}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "CLASS_NAMES = ds[\"names\"]; NUM_CLASSES = int(ds[\"nc\"])\n",
        "TEST_LABELS_DIR = Path(str(TEST_IMAGES_DIR).replace(\"/images/\",\"/labels/\"))\n",
        "PRED_DIR = Path(f\"runs/detect/{RUN_NAME}_test/labels\")\n",
        "\n",
        "# Ground truth per image (first class in .txt)\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
        "gt = {}\n",
        "for img in TEST_IMAGES_DIR.rglob(\"*\"):\n",
        "    if img.suffix.lower() in IMG_EXTS:\n",
        "        lab = (TEST_LABELS_DIR / img.name).with_suffix(\".txt\")\n",
        "        if lab.exists():\n",
        "            parts = lab.read_text().strip().split()\n",
        "            if parts:\n",
        "                gt[str(img.resolve())] = int(parts[0])\n",
        "\n",
        "# Predictions: top-confidence class per image (if any)\n",
        "pred = {}\n",
        "if PRED_DIR.exists():\n",
        "    for txt in PRED_DIR.rglob(\"*.txt\"):\n",
        "        lines = [ln.strip().split() for ln in txt.read_text().splitlines() if ln.strip()]\n",
        "        if not lines: continue\n",
        "        pairs = [(int(p[0]), float(p[-1]) if len(p)>=6 else 0.0) for p in lines]\n",
        "        best_cls, _ = max(pairs, key=lambda t: t[1])\n",
        "        stem = txt.stem\n",
        "        cands = list(TEST_IMAGES_DIR.rglob(stem + \".*\"))\n",
        "        if cands: pred[str(cands[0].resolve())] = best_cls\n",
        "\n",
        "# Assemble vectors (+ 'no_det' bucket)\n",
        "NO_DET = NUM_CLASSES\n",
        "label_names = CLASS_NAMES + [\"no_det\"]\n",
        "y_true, y_pred, per_rows = [], [], []\n",
        "for path, gt_cls in gt.items():\n",
        "    p = pred.get(path, NO_DET)\n",
        "    y_true.append(gt_cls); y_pred.append(p)\n",
        "    per_rows.append({\"image\":path,\"gt_id\":gt_cls,\"gt_name\":CLASS_NAMES[gt_cls],\n",
        "                     \"pred_id\":p,\"pred_name\":label_names[p]})\n",
        "\n",
        "cm  = confusion_matrix(y_true, y_pred, labels=list(range(len(label_names))))\n",
        "cmn = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-9)\n",
        "\n",
        "# classification_report (exclude 'no_det' from metrics)\n",
        "rep = classification_report(\n",
        "    y_true, [c if c < NUM_CLASSES else -1 for c in y_pred],\n",
        "    labels=list(range(NUM_CLASSES)),\n",
        "    target_names=CLASS_NAMES,\n",
        "    output_dict=True,\n",
        "    digits=4\n",
        ")\n",
        "rep_df = pd.DataFrame(rep).transpose()\n",
        "\n",
        "EVAL_DIR = Path(f\"runs/train/{RUN_NAME}/eval\"); EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "pd.DataFrame(per_rows).to_csv(EVAL_DIR/\"per_image_predictions.csv\", index=False)\n",
        "pd.DataFrame(cm,  index=label_names, columns=label_names).to_csv(EVAL_DIR/\"confusion_matrix_counts.csv\")\n",
        "pd.DataFrame(cmn, index=label_names, columns=label_names).to_csv(EVAL_DIR/\"confusion_matrix_normalized.csv\")\n",
        "rep_df.to_csv(EVAL_DIR/\"classification_report.csv\", index=True)\n",
        "print(\"Saved:\\n \", EVAL_DIR/\"per_image_predictions.csv\",\n",
        "      \"\\n \", EVAL_DIR/\"confusion_matrix_counts.csv\",\n",
        "      \"\\n \", EVAL_DIR/\"confusion_matrix_normalized.csv\",\n",
        "      \"\\n \", EVAL_DIR/\"classification_report.csv\")\n",
        "\n",
        "# quick heatmaps\n",
        "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
        "im0 = axes[0].imshow(cm);  axes[0].set_title(\"Confusion (counts)\")\n",
        "axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"True\")\n",
        "axes[0].set_xticks(range(len(label_names))); axes[0].set_yticks(range(len(label_names)))\n",
        "axes[0].set_xticklabels(label_names, rotation=45, ha='right'); axes[0].set_yticklabels(label_names)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        axes[0].text(j,i,int(cm[i,j]),ha='center',va='center',\n",
        "                     color='white' if cm[i,j] > cm.max()/2 else 'black')\n",
        "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "\n",
        "im1 = axes[1].imshow(cmn); axes[1].set_title(\"Confusion (normalized)\")\n",
        "axes[1].set_xlabel(\"Predicted\"); axes[1].set_ylabel(\"True\")\n",
        "axes[1].set_xticks(range(len(label_names))); axes[1].set_yticks(range(len(label_names)))\n",
        "axes[1].set_xticklabels(label_names, rotation=45, ha='right'); axes[1].set_yticklabels(label_names)\n",
        "for i in range(cmn.shape[0]):\n",
        "    for j in range(cmn.shape[1]):\n",
        "        axes[1].text(j,i,f\"{cmn[i,j]:.2f}\",ha='center',va='center',\n",
        "                     color='white' if cmn[i,j] > cmn.max()/2 else 'black')\n",
        "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwveSOBqnN9c",
        "outputId": "40896fda-f70a-475f-b440-eeec0384e475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "  runs/train/y7_tiny_raw_clean3/eval/per_image_predictions.csv \n",
            "  runs/train/y7_tiny_raw_clean3/eval/confusion_matrix_counts.csv \n",
            "  runs/train/y7_tiny_raw_clean3/eval/confusion_matrix_normalized.csv \n",
            "  runs/train/y7_tiny_raw_clean3/eval/classification_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5a) run detect on TEST (or VAL if no TEST)\n",
        "import yaml, os\n",
        "from pathlib import Path\n",
        "with open(DATA_YAML, \"r\") as f:\n",
        "    ds = yaml.safe_load(f)\n",
        "TEST_IMAGES_DIR = Path(ds.get(\"test\") or ds[\"val\"])\n",
        "BEST = Path(f\"runs/train/{RUN_NAME}/weights/best.pt\")\n",
        "\n",
        "%cd /content/yolov7\n",
        "!python detect.py --weights {str(BEST)} --img 640 --conf 0.001 \\\n",
        "  --source {str(TEST_IMAGES_DIR)} --save-txt --save-conf --name {RUN_NAME}_test\n",
        "\n",
        "# 5b) build confusion matrix + report, save CSVs\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "CLASS_NAMES = ds[\"names\"]; NUM_CLASSES = ds[\"nc\"]\n",
        "TEST_LABELS_DIR = Path(str(TEST_IMAGES_DIR).replace(\"/images/\",\"/labels/\"))\n",
        "PRED_DIR = Path(f\"runs/detect/{RUN_NAME}_test/labels\")\n",
        "\n",
        "# gt map\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
        "gt = {}\n",
        "for img in TEST_IMAGES_DIR.rglob(\"*\"):\n",
        "    if img.suffix.lower() in IMG_EXTS:\n",
        "        lab = (TEST_LABELS_DIR / img.name).with_suffix(\".txt\")\n",
        "        if lab.exists():\n",
        "            parts = lab.read_text().strip().split()\n",
        "            if parts: gt[str(img.resolve())] = int(parts[0])\n",
        "\n",
        "# pred map (top-confidence per image)\n",
        "pred = {}\n",
        "if PRED_DIR.exists():\n",
        "    for txt in PRED_DIR.rglob(\"*.txt\"):\n",
        "        lines = [ln.split() for ln in txt.read_text().splitlines() if ln.strip()]\n",
        "        if lines:\n",
        "            lines = [(int(p[0]), float(p[-1]) if len(p)>=6 else 0.0) for p in lines]\n",
        "            top = max(lines, key=lambda t: t[1])[0]\n",
        "            stem = txt.stem\n",
        "            cands = list(TEST_IMAGES_DIR.rglob(stem + \".*\"))\n",
        "            if cands: pred[str(cands[0].resolve())] = top\n",
        "\n",
        "# vectors (+ 'no_det' bucket)\n",
        "NO_DET = NUM_CLASSES\n",
        "label_names = CLASS_NAMES + [\"no_det\"]\n",
        "y_true, y_pred = [], []\n",
        "per_image_rows = []\n",
        "for k, gt_cls in gt.items():\n",
        "    p = pred.get(k, NO_DET)\n",
        "    y_true.append(gt_cls); y_pred.append(p)\n",
        "    per_image_rows.append({\"image\":k,\"gt_id\":gt_cls,\"gt_name\":CLASS_NAMES[gt_cls],\n",
        "                           \"pred_id\":p,\"pred_name\":label_names[p]})\n",
        "\n",
        "cm  = confusion_matrix(y_true, y_pred, labels=list(range(len(label_names))))\n",
        "cmn = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-9)\n",
        "rep = classification_report(\n",
        "    y_true, [x if x<NUM_CLASSES else -1 for x in y_pred],\n",
        "    labels=list(range(NUM_CLASSES)), target_names=CLASS_NAMES, output_dict=True, digits=4\n",
        ")\n",
        "rep_df = pd.DataFrame(rep).transpose()\n",
        "\n",
        "EVAL_DIR = Path(f\"runs/train/{RUN_NAME}/eval\"); EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "pd.DataFrame(per_image_rows).to_csv(EVAL_DIR/\"per_image_predictions.csv\", index=False)\n",
        "pd.DataFrame(cm,  index=label_names, columns=label_names).to_csv(EVAL_DIR/\"confusion_matrix_counts.csv\")\n",
        "pd.DataFrame(cmn, index=label_names, columns=label_names).to_csv(EVAL_DIR/\"confusion_matrix_normalized.csv\")\n",
        "rep_df.to_csv(EVAL_DIR/\"classification_report.csv\", index=True)\n",
        "print(\"Saved:\", EVAL_DIR/\"classification_report.csv\")\n",
        "\n",
        "# quick plot\n",
        "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
        "im0 = axes[0].imshow(cm);  axes[0].set_title(\"Confusion (counts)\")\n",
        "axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"True\")\n",
        "axes[0].set_xticks(range(len(label_names))); axes[0].set_yticks(range(len(label_names)))\n",
        "axes[0].set_xticklabels(label_names, rotation=45, ha='right'); axes[0].set_yticklabels(label_names)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        axes[0].text(j,i,int(cm[i,j]),ha='center',va='center',\n",
        "                     color='white' if cm[i,j] > cm.max()/2 else 'black')\n",
        "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "\n",
        "im1 = axes[1].imshow(cmn); axes[1].set_title(\"Confusion (normalized)\")\n",
        "axes[1].set_xlabel(\"Predicted\"); axes[1].set_ylabel(\"True\")\n",
        "axes[1].set_xticks(range(len(label_names))); axes[1].set_yticks(range(len(label_names)))\n",
        "axes[1].set_xticklabels(label_names, rotation=45, ha='right'); axes[1].set_yticklabels(label_names)\n",
        "for i in range(cmn.shape[0]):\n",
        "    for j in range(cmn.shape[1]):\n",
        "        axes[1].text(j,i,f\"{cmn[i,j]:.2f}\",ha='center',va='center',\n",
        "                     color='white' if cmn[i,j] > cmn.max()/2 else 'black')\n",
        "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNj2ykTReIax",
        "outputId": "6b913f89-8483-41b6-cd4f-016db1457d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "Namespace(weights=['runs/train/y7_tiny_raw_clean3/weights/best.pt'], source='/content/drive/MyDrive/DLRV/DATASET_YOLO_RAW_CLEAN/images/test', img_size=640, conf_thres=0.001, iou_thres=0.45, device='', view_img=False, save_txt=True, save_conf=True, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='y7_tiny_raw_clean3_test', exist_ok=False, no_trace=False)\n",
            "YOLOR üöÄ v0.1-128-ga207844 torch 2.8.0+cu126 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"/content/yolov7/detect.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov7/models/experimental.py\", line 252, in attempt_load\n",
            "    ckpt = torch.load(w, map_location=map_location)  # load\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1529, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray._reconstruct])` or the `torch.serialization.safe_globals([numpy._core.multiarray._reconstruct])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: runs/train/y7_tiny_raw_clean3/eval/classification_report.csv\n"
          ]
        }
      ]
    }
  ]
}